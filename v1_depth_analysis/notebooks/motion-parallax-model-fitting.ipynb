{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import suite2p\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Sequence, Dict, Any\n",
    "from scipy.stats import kde, pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from scipy.signal import find_peaks\n",
    "import cottage_analysis as cott\n",
    "from cottage_analysis.imaging.common import align_timestamps, find_frames\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy\n",
    "import motion_model as mm\n",
    "from motion_model.util import lag_tensor\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import graphviz\n",
    "import optax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data RS & OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# --------------------- filepath ---------------------\n",
    "# ----------------------------------------------------\n",
    "rawdata_root = '/camp/lab/znamenskiyp/data/instruments/raw_data/projects/'\n",
    "root = '/camp/lab/znamenskiyp/home/shared/projects/'\n",
    "project = 'hey2_3d-vision_20210716'\n",
    "data_dir = ''\n",
    "mouse = 'PZAH2.1b'\n",
    "session = 'S20210916'\n",
    "recording = 'R163430'\n",
    "protocol = 'SphereSparseNoise'\n",
    "suite2p_dir = 'suite2p_rois_0/suite2p/plane0/'\n",
    "trace_dir = 'suite2p_traces_0/'\n",
    "\n",
    "def generate_filefolder(root, rawdata_root, project, data_dir, mouse, session, recording, protocol):\n",
    "    rawdata_folder = rawdata_root + project + '/' + data_dir + mouse + '/' + session + '/' + recording + '_' + protocol +'/'\n",
    "    preprocess_folder = root + project + '/' + data_dir + mouse + '/' + session + '/' + recording + '_' + protocol +'/'\n",
    "    analysis_folder = root + project + '/' + data_dir + 'Analysis/' + mouse + '/' + session + '/' + recording + '_' + protocol +'/'\n",
    "    \n",
    "    return rawdata_folder, preprocess_folder, analysis_folder\n",
    "\n",
    "def generate_suite2p_folder(root, project, data_dir, mouse, session, recording, protocol, suite2p_dir, trace_dir):\n",
    "    suite2p_folder = root + project + '/' + data_dir + mouse + '/' + session + '/' + suite2p_dir\n",
    "    protocol_folder = root + project + '/' + data_dir + mouse + '/' + session + '/' + recording + '_' + protocol +'/'\n",
    "    trace_folder = protocol_folder +  protocol + '_' + trace_dir\n",
    "    \n",
    "    return suite2p_folder, protocol_folder, trace_folder\n",
    "\n",
    "\n",
    "rawdata_folder, preprocess_folder, analysis_folder = generate_filefolder(root, rawdata_root, project, data_dir, mouse, session, recording, protocol)\n",
    "\n",
    "suite2p_folder, protocol_folder, trace_folder = generate_suite2p_folder(root, project, data_dir, mouse, session, recording, protocol, suite2p_dir, trace_dir)\n",
    "\n",
    "if not os.path.exists(analysis_folder):\n",
    "    os.makedirs(analysis_folder)\n",
    "\n",
    "    \n",
    "# ----------------------------------------------------\n",
    "# --------------------- Load files ---------------------\n",
    "# ----------------------------------------------------\n",
    "#Â Load parameters\n",
    "with open(protocol_folder+'img_VS.pickle', 'rb') as handle:\n",
    "    img_VS = pickle.load(handle)\n",
    "    \n",
    "img_VS['Stim'] = np.nan\n",
    "img_VS.loc[img_VS.Depth.notnull(), 'Stim'] = 1\n",
    "img_VS.loc[img_VS.Depth<0, 'Stim'] = 0\n",
    "img_VS.loc[((img_VS[img_VS.Depth<0]).index.values-1),'Stim'] = 0\n",
    "\n",
    "img_VS_simple = img_VS[(img_VS['Stim'].diff()!=0) & (img_VS['Stim'].notnull())]\n",
    "img_VS_simple.Depth = np.round(img_VS_simple.Depth,2)\n",
    "\n",
    "# Find stim frames\n",
    "depth_list = [0.2, 0.63, 2]\n",
    "stim_dict = {}\n",
    "for istim in depth_list:  \n",
    "    stim_dict['stim'+str(istim)] = {}\n",
    "    stim_dict['stim'+str(istim)]['start'] = img_VS_simple[(img_VS_simple['Depth']==istim) & (img_VS_simple['Stim']==1)].index.values\n",
    "    stim_dict['stim'+str(istim)]['stop'] = img_VS_simple[(img_VS_simple['Depth']==istim) & (img_VS_simple['Stim']==0)].index.values\n",
    "    \n",
    "blank_points = img_VS_simple.index.values[1:-1]\n",
    "stim_dict['blank'] = {}\n",
    "stim_dict['blank']['start'] = blank_points[0::2] + 1\n",
    "stim_dict['blank']['stop'] = blank_points[1::2] - 1\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# --------------------- RS, OF, dFF ---------------------\n",
    "# ----------------------------------------------------\n",
    "# Utils\n",
    "def find_min_trial_num_all_depths(stim_dict, depth_list, isStim=True):\n",
    "    if isStim:\n",
    "        trial_nums = []\n",
    "        for idepth in range(len(depth_list)):\n",
    "            depth = depth_list[idepth]\n",
    "            frame_dict = stim_dict['stim'+str(depth)]\n",
    "            trial_nums.append(len(frame_dict['start']))\n",
    "        trial_nums = np.array(trial_nums)\n",
    "        if not np.all(trial_nums==trial_nums[0]):\n",
    "            print('Trials nums are not the same. Take the min trial num.')\n",
    "        trial_num = np.min(trial_nums)\n",
    "    else: \n",
    "        trial_num = len(stim_dict['blank']['stop'])    \n",
    "    return trial_num\n",
    "\n",
    "def find_min_frame_num_per_trial(depth_list, stim_dict, isStim=True):\n",
    "    if isStim: \n",
    "        trial_num = find_min_trial_num_all_depths(stim_dict, depth_list)\n",
    "        frame_num_arr = np.zeros((len(depth_list),trial_num))\n",
    "        for idepth in range(len(depth_list)):\n",
    "            for itrial in range(trial_num):\n",
    "                frame_start = stim_dict['stim'+str(depth_list[idepth])]['start'][itrial]\n",
    "                frame_stop = stim_dict['stim'+str(depth_list[idepth])]['stop'][itrial]\n",
    "                frame_num = frame_stop - frame_start+1\n",
    "                frame_num_arr[idepth, itrial] = frame_num\n",
    "    else:\n",
    "        trial_num = find_min_trial_num_all_depths(stim_dict, depth_list, isStim=False)\n",
    "        frame_num_arr = np.zeros(trial_num)\n",
    "        for itrial in range(trial_num):\n",
    "            frame_start = stim_dict['blank']['start'][itrial]\n",
    "            frame_stop = stim_dict['blank']['stop'][itrial]\n",
    "            frame_num = frame_stop - frame_start+1\n",
    "            frame_num_arr[itrial] = frame_num\n",
    "    return int(np.min(frame_num_arr))\n",
    "\n",
    "# Create an array to store the traces for each roi, format: depth x trial x frames_per_trial\n",
    "def create_trace_arr_per_roi(which_roi, dffs, depth_list, stim_dict, isStim=True, blank_period=0, frame_rate=30):\n",
    "    trial_num = find_min_trial_num_all_depths(stim_dict, depth_list, isStim=isStim)\n",
    "    frame_num_pertrial = find_min_frame_num_per_trial(depth_list, stim_dict, isStim=isStim)\n",
    "    frame_num_pertrial = frame_num_pertrial + blank_period*frame_rate*2\n",
    "    dff = dffs[which_roi,:]\n",
    "    if isStim:\n",
    "        trace_arr = np.zeros((len(depth_list),trial_num, frame_num_pertrial))\n",
    "        for idepth in range(0,len(depth_list)):\n",
    "            depth = depth_list[idepth]\n",
    "            for itrial in range(0, trial_num):\n",
    "                frame_start = stim_dict['stim'+str(depth)]['start'][itrial] - blank_period*frame_rate\n",
    "                trace_arr[idepth, itrial,:] = dff[frame_start:(frame_start+frame_num_pertrial)]  \n",
    "    else:\n",
    "        trace_arr = np.zeros((1,trial_num, frame_num_pertrial))\n",
    "        for itrial in range(0, trial_num):\n",
    "            frame_start = stim_dict['blank']['start'][itrial]\n",
    "            trace_arr[0, itrial,:] = dff[frame_start:(frame_start+frame_num_pertrial)]\n",
    "    return trace_arr\n",
    "\n",
    "# Create an array to store the speed for each trial, format: depth x trial x frames_per_trial\n",
    "def create_speed_arr(speeds, depth_list, stim_dict, isStim=True, blank_period=0, frame_rate=30):\n",
    "    trial_num = find_min_trial_num_all_depths(stim_dict, depth_list, isStim=isStim)\n",
    "    frame_num_pertrial = find_min_frame_num_per_trial(depth_list, stim_dict, isStim=isStim)\n",
    "    frame_num_pertrial = frame_num_pertrial + blank_period*frame_rate*2\n",
    "    if isStim:\n",
    "        speed_arr = np.zeros((len(depth_list),trial_num, frame_num_pertrial))\n",
    "        for idepth in range(0,len(depth_list)):\n",
    "            depth = depth_list[idepth]\n",
    "            for itrial in range(0, trial_num):\n",
    "                frame_start = stim_dict['stim'+str(depth)]['start'][itrial] - blank_period*frame_rate\n",
    "                speed_arr[idepth, itrial,:] = speeds[frame_start:(frame_start+frame_num_pertrial)]\n",
    "    else:\n",
    "        speed_arr = np.zeros((1,trial_num, frame_num_pertrial))\n",
    "        for itrial in range(0, trial_num):\n",
    "            frame_start = stim_dict['blank']['start'][itrial]\n",
    "            speed_arr[0, itrial,:] = speeds[frame_start:(frame_start+frame_num_pertrial)]   \n",
    "    return speed_arr\n",
    "\n",
    "def segment_arr(arr_idx, segment_size):\n",
    "    batch_num = len(arr_idx)//segment_size\n",
    "    segment_starts = np.arange(0,batch_num*segment_size+1,segment_size)\n",
    "    segment_ends = np.arange(segment_size,batch_num*segment_size+segment_size,segment_size)\n",
    "    if len(arr_idx)%segment_size!=0:\n",
    "        segment_ends = np.concatenate((segment_ends, (arr_idx[-1]+1).reshape(-1)))\n",
    "    segment_starts = (segment_starts+arr_idx[0])[:len(segment_ends)]\n",
    "    segment_ends = segment_ends+arr_idx[0]\n",
    "    return segment_starts, segment_ends \n",
    "\n",
    "\n",
    "\n",
    "# Speed (Unit: cm/s)\n",
    "speeds = img_VS.EyeZ.diff()/img_VS.HarpTime.diff()*100\n",
    "speeds[0] = 0\n",
    "\n",
    "# Process speed: take abs, thresholding\n",
    "def thr(arr, thr):\n",
    "#     arr = np.abs(arr)\n",
    "    arr[arr<thr] = thr\n",
    "    \n",
    "    return arr\n",
    "\n",
    "rs_thr = 0.01\n",
    "speeds = thr(speeds, thr=rs_thr)\n",
    "\n",
    "\n",
    "# Optic flow (Unit: rad/s)\n",
    "all_depths = img_VS.Depth.replace(-99.99,np.nan)\n",
    "optics = speeds/(all_depths*100)\n",
    "optics = np.array(optics)\n",
    "\n",
    "\n",
    "# Process RS & OF data\n",
    "#Â Lag array\n",
    "frame_rate = 30\n",
    "rs_lag_min = -0.5\n",
    "rs_lag_max = 1\n",
    "of_lag_min = 0\n",
    "of_lag_max = 1\n",
    "choose_trials = 50\n",
    "low_value_pcent = 0.9\n",
    "\n",
    "rs_lags = lag_tensor(speeds, nlags_min=int(frame_rate*rs_lag_min), nlags_max = int(frame_rate*rs_lag_max))\n",
    "of_lags = lag_tensor(optics, nlags_min=int(frame_rate*of_lag_min), nlags_max = int(frame_rate*of_lag_max))\n",
    "\n",
    "# For each lag column, find the rows for stim frames\n",
    "(ndepths, ntrials, nframes) = create_speed_arr(speeds, depth_list, stim_dict, isStim=True).shape\n",
    "rs_stim = np.zeros((rs_lags.shape[1], ndepths, ntrials, nframes))\n",
    "of_stim = np.zeros((of_lags.shape[1], ndepths, ntrials, nframes))\n",
    "for icol in range(rs_lags.shape[1]):\n",
    "    rs_stim[icol] = create_speed_arr(rs_lags[:,icol], depth_list, stim_dict, isStim=True)\n",
    "for icol in range(of_lags.shape[1]):\n",
    "    of_stim[icol] = create_speed_arr(of_lags[:,icol], depth_list, stim_dict, isStim=True)\n",
    "    \n",
    "# replace nan with 0: HOW TO DEAL WITH NAN IN OF? \n",
    "# Thresholding OF\n",
    "of_thr = 0.0001\n",
    "of_stim = np.nan_to_num(of_stim)\n",
    "of_stim = thr(of_stim, thr=of_thr)\n",
    "\n",
    "# Choose trials\n",
    "rs_stim = rs_stim[:,:,:choose_trials,:]\n",
    "of_stim = of_stim[:,:,:choose_trials,:]\n",
    "rs_stim = rs_stim.reshape(rs_stim.shape[0],-1).T\n",
    "of_stim = of_stim.reshape(of_stim.shape[0],-1).T\n",
    "\n",
    "# Take out rows with lots of low values\n",
    "def discard_low_values_rows(arr, thr, low_value_pcent):\n",
    "    low_value_num = int(arr.shape[1]*low_value_pcent)\n",
    "    [discarded_irows] = np.array(np.where(np.array([np.sum(arr[i,:]<=thr) for i in range(arr.shape[0])]).flatten()>low_value_num))\n",
    "    filtered_arr = np.delete(arr, discarded_irows, 0)\n",
    "    return discarded_irows, filtered_arr\n",
    "\n",
    "discarded_irows, rs_stim = discard_low_values_rows(rs_stim, rs_thr, low_value_pcent)\n",
    "of_stim = np.delete(of_stim, discarded_irows,0)\n",
    "\n",
    "\n",
    "#Â Log RS & OF\n",
    "rs_stim_analysis = np.log(rs_stim)\n",
    "of_stim_analysis = np.log(of_stim)\n",
    "\n",
    "rs_x = rs_stim_analysis\n",
    "of_x = of_stim_analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# --------------------- Load files ---------------------\n",
    "# ----------------------------------------------------\n",
    "\n",
    "#Â Load suite2p extracted traces\n",
    "# F = np.load(suite2p_folder+'F.npy', allow_pickle=True)\n",
    "# Fneu = np.load(suite2p_folder+'Fneu.npy', allow_pickle=True)\n",
    "# spks = np.load(suite2p_folder+'spks.npy', allow_pickle=True)\n",
    "# stat = np.load(suite2p_folder+'stat.npy', allow_pickle=True)\n",
    "# ops =  np.load(suite2p_folder+'ops.npy', allow_pickle=True)\n",
    "# ops = ops.item()\n",
    "iscell = np.load(suite2p_folder+'iscell.npy', allow_pickle=True)[:,0]\n",
    "# output_op = ops\n",
    "\n",
    "f_cells = np.load(Path(trace_folder).joinpath('F.npy'))\n",
    "# f_neus = np.load(Path(trace_folder).joinpath('Fneu.npy'))\n",
    "# spks = np.load(Path(trace_folder).joinpath('spks.npy'))\n",
    "f_ast = np.load(Path(trace_folder).joinpath('Fast.npy'))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# --------------------- Process dFF ---------------------\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# All_rois\n",
    "which_rois = (np.arange(f_cells.shape[0]))[iscell.astype('bool')]\n",
    "\n",
    "# dF/F\n",
    "def dFF(f_cells):\n",
    "    f_mean = np.average(f_cells,axis=1).reshape(-1,1)\n",
    "    dffs = (f_cells-f_mean)/f_mean\n",
    "    return dffs\n",
    "dffs = dFF(f_cells)\n",
    "dffs_ast = dFF(f_ast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify data \n",
    "from random import shuffle\n",
    "def stratify_index(data, batch_size, nbatches=None):\n",
    "    '''Stratify data into mini batches'''\n",
    "    nrows = data.shape[0]\n",
    "    rows = np.arange(nrows)   \n",
    "    shuffle(rows)\n",
    "    stratified_idx = []\n",
    "    if nbatches!=None:\n",
    "        batch_size = nrows//nbatches\n",
    "    else:\n",
    "        nbatches = int(np.ceil(nrows/batch_size))\n",
    "    for i in range(nbatches-1):\n",
    "        stratified_idx.append(rows[i*batch_size:(i+1)*batch_size])\n",
    "    stratified_idx.append(rows[batch_size*(nbatches-1):])\n",
    "    return stratified_idx\n",
    "\n",
    "\n",
    "# Training\n",
    "@jax.jit\n",
    "def update(params, rs, of, spikes, opt_state):\n",
    "    \"\"\"Apply optimizer.\"\"\"\n",
    "    nll, grads = jax.value_and_grad(mm.model.rs_of_integration_loss)(params, rs, of, spikes)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, nll, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "lr=1e-2\n",
    "nepoches = 10\n",
    "batch_size = 1000\n",
    "nsteps = 1000\n",
    "save_prefix = 'plots/modelling_new/'\n",
    "if not os.path.exists(analysis_folder+save_prefix):\n",
    "    os.makedirs(analysis_folder+save_prefix)\n",
    "\n",
    "rs_x = rs_x\n",
    "of_x = of_x\n",
    "nbatches = int(np.ceil(len(spikes)/batch_size))\n",
    "\n",
    "# Choose ROI - Process dFF\n",
    "rois_mins, rois_maxs = segment_arr(np.arange(0,len(which_rois),1), segment_size = 10)\n",
    "for rois_min, rois_max in zip(rois_mins, rois_maxs):\n",
    "    select_rois = which_rois[rois_min:rois_max]\n",
    "    with PdfPages(analysis_folder+save_prefix+'roi'+str(rois_min)+'-'+str(rois_max)+'.pdf') as pdf:\n",
    "        for choose_roi in select_rois:\n",
    "            loss_history = []\n",
    "            grads_history = []\n",
    "\n",
    "            trace_arr = create_trace_arr_per_roi(choose_roi, dffs, depth_list, stim_dict, isStim=True, blank_period=0, frame_rate=30)\n",
    "            # Choose trials\n",
    "            trace_stim = trace_arr[:,:choose_trials,:]\n",
    "            trace_stim = trace_stim.flatten().reshape(-1,1)\n",
    "            # Take out rows with lots of low values\n",
    "            trace_stim = np.delete(trace_stim, discarded_irows,0)\n",
    "            spikes = trace_stim\n",
    "\n",
    "            # Initialization\n",
    "            rng_key = jax.random.PRNGKey(seed)\n",
    "            init_params = mm.model.rs_of_integration.init(rng=rng_key, rs=rs_x, of=of_x)\n",
    "            params = init_params\n",
    "            opt = optax.adam(lr)\n",
    "            opt_state = opt.init(params)\n",
    "\n",
    "\n",
    "            for iepoch in range(nepoches):\n",
    "                stratified_idx = stratify_index(spikes,batch_size=batch_size)\n",
    "\n",
    "                for ibatch in range(nbatches):\n",
    "                    spikes_mini = spikes[stratified_idx[ibatch]]\n",
    "                    rs_x_mini = rs_x[stratified_idx[ibatch]]\n",
    "                    of_x_mini = of_x[stratified_idx[ibatch]]\n",
    "\n",
    "\n",
    "                    for step in range(nsteps):\n",
    "                        params, opt_state, nll, grads = update(params, jnp.array(rs_x_mini, dtype=jnp.float32), jnp.array(of_x_mini, dtype=jnp.float32), jnp.array(spikes_mini, dtype=jnp.float32), opt_state)\n",
    "            #             if step % 20 == 0:\n",
    "            #                 print(f\"[Step {step}] nll: {nll:.3f}\")\n",
    "                        loss_history.append(nll)\n",
    "                    print(f'[batch {ibatch}] nll: {nll:.3f}')\n",
    "                print(f'[epoch {iepoch}] nll: {nll:.3f}')\n",
    "\n",
    "\n",
    "            # ---Plotting---\n",
    "            # R-squared\n",
    "            def calculate_R_squared(actual_data, predicted_data):\n",
    "                actual_data = np.array(actual_data)\n",
    "                predicted_data = np.array(predicted_data)\n",
    "                explained_var = np.sum((predicted_data-np.mean(actual_data))**2)\n",
    "                total_var = np.sum((actual_data - np.mean(actual_data))**2)\n",
    "                R_squared = explained_var/total_var\n",
    "                return R_squared\n",
    "\n",
    "            plot_rows = 5\n",
    "            plot_cols = 4\n",
    "            plot_start = 0\n",
    "            plot_end = 1000\n",
    "\n",
    "            plt.figure(figsize=(7*plot_cols,5*plot_rows))\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[0,0])\n",
    "            plt.plot(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))])\n",
    "            plt.title('ROI'+str(choose_roi)+' RS cm/s')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[0,1])\n",
    "            plt.hist(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))],bins=50)\n",
    "            plt.title('Hist RS')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[1,0])\n",
    "            plt.plot(np.log(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))]))\n",
    "            plt.title('log(RS) cm/s')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[1,1])\n",
    "            plt.hist(np.log(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))]),bins=50)\n",
    "            plt.title('Hist log(RS)')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[0,2])\n",
    "            plt.plot(of_stim[:,int(frame_rate*np.abs(of_lag_min))])\n",
    "            plt.title('OF rad/s')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[0,3])\n",
    "            plt.hist(of_stim[:,int(frame_rate*np.abs(of_lag_min))],bins=50)\n",
    "            plt.title('Hist OF')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[1,2])\n",
    "            plt.plot(np.log(of_stim[:,int(frame_rate*np.abs(of_lag_min))]))\n",
    "            plt.title('log(OF) rad/s')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[1,3])\n",
    "            plt.hist(np.log(of_stim[:,int(frame_rate*np.abs(of_lag_min))]),bins=50)\n",
    "            plt.title('Hist log(OF)')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[2,0], colspan=2)\n",
    "            loss_history = np.array(loss_history)\n",
    "            plt.plot(loss_history[loss_history<10000])\n",
    "            plt.xlabel('steps')\n",
    "            plt.ylabel('loss')\n",
    "            plt.title('Loss')\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[2,2], colspan=2)\n",
    "            plt.plot(spikes, label='Data')\n",
    "            plt.plot(mm.model.rs_of_integration.apply(params=params, rs=rs_x, of=of_x), label='Model fit')\n",
    "            R_squared = calculate_R_squared(actual_data=spikes, predicted_data=mm.model.rs_of_integration.apply(params=params, rs=rs_x, of=of_x))\n",
    "            plt.title('Data vs model fit, loss: ' +str(np.around(loss_history[-1]))+' R2: '+str(R_squared))\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[3,0], colspan=2)\n",
    "            x_axis = np.arange(-20,20,0.001)\n",
    "            plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, params['gaussian_module']['mu'], np.exp(params['gaussian_module']['log_sigma'])),label='Trained')\n",
    "            plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, init_params['gaussian_module']['mu'], np.exp(params['gaussian_module']['log_sigma'])),label='Init')\n",
    "            plt.title('Gaussian kernel for RS, mu='+str(np.round(np.array(params['gaussian_module']['mu']),2))+' log_sigma='+str(np.round(np.array(params['gaussian_module']['log_sigma']),2)))\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[3,2], colspan=2)\n",
    "            plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, params['gaussian_module_1']['mu'], np.exp(params['gaussian_module_1']['log_sigma'])),label='Trained')\n",
    "            plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, init_params['gaussian_module_1']['mu'], np.exp(params['gaussian_module_1']['log_sigma'])),label='Init')\n",
    "            plt.title('Gaussian kernel for OF, mu='+str(np.round(np.array(params['gaussian_module_1']['mu']),2))+' log_sigma='+str(np.round(np.array(params['gaussian_module_1']['log_sigma']),2)))\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[4,0], colspan=2)\n",
    "            plt.plot(np.linspace(rs_lag_min,rs_lag_max,int(frame_rate*(rs_lag_max-rs_lag_min))),params['linear']['w'], label='Trained')\n",
    "            plt.plot(np.linspace(-0.5,1,int(frame_rate*(1-(-0.5)))),init_params['linear']['w'], label='Init')\n",
    "            plt.xlabel('lags')\n",
    "            plt.ylabel('w')\n",
    "            plt.title('Linear kernel for RS')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot2grid([plot_rows,plot_cols],[4,2], colspan=2)\n",
    "            plt.plot(np.linspace(of_lag_min,of_lag_max,int(frame_rate*(of_lag_max-of_lag_min))),params['linear_1']['w'], label='Trained')\n",
    "            plt.plot(np.linspace(of_lag_min,of_lag_max,int(frame_rate*(of_lag_max-of_lag_min))),init_params['linear_1']['w'], label='Init')\n",
    "            plt.xlabel('lags')\n",
    "            plt.ylabel('w')\n",
    "            plt.title('Linear kernel for OF')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.tight_layout(pad=1)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared\n",
    "def calculate_R_squared(actual_data, predicted_data):\n",
    "    actual_data = np.array(actual_data)\n",
    "    predicted_data = np.array(predicted_data)\n",
    "    explained_var = np.sum((predicted_data-np.mean(actual_data))**2)\n",
    "    total_var = np.sum((actual_data - np.mean(actual_data))**2)\n",
    "    R_squared = explained_var/total_var\n",
    "    return R_squared\n",
    "\n",
    "plot_rows = 5\n",
    "plot_cols = 4\n",
    "plot_start = 0\n",
    "plot_end = 1000\n",
    "\n",
    "plt.figure(figsize=(7*plot_cols,5*plot_rows))\n",
    "plt.subplot2grid([plot_rows,plot_cols],[0,0])\n",
    "plt.plot(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))])\n",
    "plt.title('RS cm/s')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[0,1])\n",
    "plt.hist(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))],bins=50)\n",
    "plt.title('Hist RS')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[1,0])\n",
    "plt.plot(np.log(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))]))\n",
    "plt.title('log(RS) cm/s')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[1,1])\n",
    "plt.hist(np.log(rs_stim[:,int(frame_rate*np.abs(rs_lag_min))]),bins=50)\n",
    "plt.title('Hist log(RS)')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[0,2])\n",
    "plt.plot(of_stim[:,int(frame_rate*np.abs(of_lag_min))])\n",
    "plt.title('OF rad/s')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[0,3])\n",
    "plt.hist(of_stim[:,int(frame_rate*np.abs(of_lag_min))],bins=50)\n",
    "plt.title('Hist OF')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[1,2])\n",
    "plt.plot(np.log(of_stim[:,int(frame_rate*np.abs(of_lag_min))]))\n",
    "plt.title('log(OF) rad/s')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[1,3])\n",
    "plt.hist(np.log(of_stim[:,int(frame_rate*np.abs(of_lag_min))]),bins=50)\n",
    "plt.title('Hist log(OF)')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[2,0], colspan=2)\n",
    "loss_history = np.array(loss_history)\n",
    "plt.plot(loss_history[loss_history<10000])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[2,2], colspan=2)\n",
    "plt.plot(spikes, label='Data')\n",
    "plt.plot(mm.model.rs_of_integration.apply(params=params, rs=rs_x, of=of_x), label='Model fit')\n",
    "R_squared = calculate_R_squared(actual_data=spikes, predicted_data=mm.model.rs_of_integration.apply(params=params, rs=rs_x, of=of_x))\n",
    "plt.title('Data vs model fit, loss: ' +str(np.around(loss_history[-1]))+' R2: '+str(R_squared))\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[3,0], colspan=2)\n",
    "x_axis = np.arange(-20,20,0.001)\n",
    "plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, params['gaussian_module']['mu'], np.exp(params['gaussian_module']['log_sigma'])),label='Trained')\n",
    "plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, init_params['gaussian_module']['mu'], np.exp(params['gaussian_module']['log_sigma'])),label='Init')\n",
    "plt.title('Gaussian kernel for RS, mu='+str(np.round(np.array(params['gaussian_module']['mu']),2))+' log_sigma='+str(np.round(np.array(params['gaussian_module']['log_sigma']),2)))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[3,2], colspan=2)\n",
    "plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, params['gaussian_module_1']['mu'], np.exp(params['gaussian_module_1']['log_sigma'])),label='Trained')\n",
    "plt.plot(x_axis, scipy.stats.norm.pdf(x_axis, init_params['gaussian_module_1']['mu'], np.exp(params['gaussian_module_1']['log_sigma'])),label='Init')\n",
    "plt.title('Gaussian kernel for OF, mu='+str(np.round(np.array(params['gaussian_module_1']['mu']),2))+' log_sigma='+str(np.round(np.array(params['gaussian_module_1']['log_sigma']),2)))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[4,0], colspan=2)\n",
    "plt.plot(np.linspace(rs_lag_min,rs_lag_max,int(frame_rate*(rs_lag_max-rs_lag_min))),params['linear']['w'], label='Trained')\n",
    "plt.plot(np.linspace(-0.5,1,int(frame_rate*(1-(-0.5)))),init_params['linear']['w'], label='Init')\n",
    "plt.xlabel('lags')\n",
    "plt.ylabel('w')\n",
    "plt.title('Linear kernel for RS')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot2grid([plot_rows,plot_cols],[4,2], colspan=2)\n",
    "plt.plot(np.linspace(of_lag_min,of_lag_max,int(frame_rate*(of_lag_max-of_lag_min))),params['linear_1']['w'], label='Trained')\n",
    "plt.plot(np.linspace(of_lag_min,of_lag_max,int(frame_rate*(of_lag_max-of_lag_min))),init_params['linear_1']['w'], label='Init')\n",
    "plt.xlabel('lags')\n",
    "plt.ylabel('w')\n",
    "plt.title('Linear kernel for OF')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout(pad=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('params_sim.pickle', 'wb') as handle:\n",
    "    pickle.dump(params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('params_sim.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
