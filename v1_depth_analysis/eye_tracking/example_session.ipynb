{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example session\n",
    "\n",
    "Notebook to try stuff before creating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select session\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.measure import EllipseModel\n",
    "import flexiznam as flz\n",
    "from v1_depth_analysis.config import PROJECT\n",
    "import v1_depth_analysis as vda\n",
    "from cottage_analysis.eye_tracking import analysis as analeyesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = Path(flz.PARAMETERS[\"data_root\"][\"raw\"])\n",
    "processed_path = Path(flz.PARAMETERS[\"data_root\"][\"processed\"])\n",
    "flm_sess = flz.get_flexilims_session(project_id=PROJECT)\n",
    "\n",
    "recordings = vda.get_recordings(protocol=\"SpheresPermTubeReward\", flm_sess=flm_sess)\n",
    "datasets = vda.get_datasets(\n",
    "    recordings, dataset_type=\"camera\", dataset_name_contains=\"_eye\", flm_sess=flm_sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = [ds for ds in  datasets if ds.genealogy[1] in [\"S20220419\", \"S20220421\"]]\n",
    "camera = [ds for ds in camera if \"right\" in ds.dataset_name][3]\n",
    "print(f\"Analysing {' from '.join(camera.genealogy[::-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_res, ellipse = analeyesis.get_data(\n",
    "    camera,\n",
    "    flexilims_session=flm_sess,\n",
    "    likelihood_threshold=0.88,\n",
    "    rsquare_threshold=0.99,\n",
    "    error_threshold=3,\n",
    ")\n",
    "ellipse.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot movie with ellipse fit\n",
    "camera_save_folder = camera.path_full / camera.dataset_name\n",
    "target_file =  camera_save_folder / \"eye_tracking_ellipse_overlay.mp4\"\n",
    "video_file = camera.path_full / camera.extra_attributes['video_file']\n",
    "if False:\n",
    "    analeyesis.plot_movie(camera,\n",
    "    target_file,\n",
    "    start_frame=0,\n",
    "    duration=6,\n",
    "    dlc_res=None,\n",
    "    ellipse=None,\n",
    "    vmax=None,\n",
    "    vmin=None,\n",
    "    playback_speed=4,\n",
    ")\n",
    "else:\n",
    "    cam_data = cv2.VideoCapture(str(video_file))\n",
    "    ret, frame = cam_data.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cam_data.release()\n",
    "    plt.imshow(gray, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of fit quality\n",
    "\n",
    "import seaborn as sns\n",
    "# DLC likelihood\n",
    "data=dlc_res.xs('likelihood', axis='columns', level=2)\n",
    "data.columns = data.columns.droplevel('scorer')\n",
    "ax = sns.displot(\n",
    "    data.drop(\n",
    "        axis=\"columns\",\n",
    "        labels=[\n",
    "            \"reflection\",\n",
    "            \"left_eye_corner\",\n",
    "            \"right_eye_corner\",\n",
    "            \"top_eye_lid\",\n",
    "            \"bottom_eye_lid\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "plt.gca().set_xlabel(\"DLC likelihood\")\n",
    "plt.gcf().set_size_inches(5,5)\n",
    "likelihood_threshold = 0.88\n",
    "plt.axvline(likelihood_threshold, color='k')\n",
    "plt.xlim(0.8, 1)\n",
    "sns.jointplot(data=ellipse[ellipse.valid], x='error', y='rsquare')\n",
    "sns.jointplot(data=ellipse[ellipse.valid], x='error', y='dlc_avg_likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "elli = ellipse[ellipse.valid]\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "sc = ax.scatter(elli.centre_x, elli.centre_y, c=np.rad2deg(elli.angle), vmax=70, vmin=50)\n",
    "cb = fig.colorbar(ax=ax, mappable=sc)\n",
    "cb.set_label('Ellipse angle (degrees)')\n",
    "ax.set_xlabel('Ellipse centre X (pixels)')\n",
    "ax.set_ylabel('Ellipse centre Y (pixels)')\n",
    "ax.set_aspect('equal')\n",
    "ax.invert_yaxis()\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "\n",
    "count, bx, by = np.histogram2d(elli.centre_x, elli.centre_y, bins=(70, 70))\n",
    "h, bx, by = np.histogram2d(elli.centre_x, elli.centre_y, weights=np.rad2deg(elli.angle), bins=(bx, by))\n",
    "h[count < 1] = np.nan\n",
    "img = ax.imshow((h/count).T, extent=(bx[0], bx[-1], by[0], by[-1]), vmin=55, vmax=65)\n",
    "cb = fig.colorbar(mappable=img, ax=ax)\n",
    "cb.set_label('Ellipse angle (degrees)')\n",
    "ax.set_xlabel('Ellipse centre X (pixels)')\n",
    "ax.set_ylabel('Ellipse centre Y (pixels)')\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "h, bx, by = np.histogram2d(elli.centre_x, elli.centre_y, weights=elli.major_radius/elli.minor_radius, bins=(bx, by))\n",
    "h[count < 1] = np.nan\n",
    "img = ax.imshow((h/count).T, extent=(bx[0], bx[-1], by[0], by[-1]), vmin=1.1, vmax=1.4)\n",
    "cb = fig.colorbar(mappable=img, ax=ax)\n",
    "cb.set_label('Ellipse axes ratio')\n",
    "ax.set_xlabel('Ellipse centre X (pixels)')\n",
    "ax.set_ylabel('Ellipse centre Y (pixels)')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "def get_stim_info(rec):\n",
    "    sess_children = flz.get_children(parent_id=rec.origin_id, flexilims_session=flm_sess, children_datatype='recording')\n",
    "    rec_closeloop = sess_children[sess_children.protocol==\"SpheresPermTubeReward\"]\n",
    "    assert len(rec_closeloop) == 1\n",
    "    rec_closeloop = rec_closeloop.iloc[0]\n",
    "    rec_playback =  sess_children[sess_children.protocol==\"SpheresPermTubeRewardPlayback\"]\n",
    "    if len(rec_playback):\n",
    "        rec_playback = rec_playback.iloc[0]\n",
    "        print(f\"Analysing {rec_closeloop.name}\\n     and {rec_playback.name}\", flush=True)\n",
    "    else:\n",
    "        rec_playback = 'NO PLAYBACK'\n",
    "        print(f\"Analysing {rec_closeloop.name} (no closed loop)\", flush=True)\n",
    "    \n",
    "    sess_ds =  flz.get_children(parent_id=rec_closeloop.origin_id, flexilims_session=flm_sess, children_datatype='dataset')\n",
    "    suite_2p = sess_ds[sess_ds.dataset_type=='suite2p_rois']\n",
    "    assert len(suite_2p) == 1\n",
    "    suite_2p = flz.Dataset.from_flexilims(data_series=suite_2p.iloc[0], flexilims_session=flm_sess)\n",
    "    \n",
    "    ops = np.load(suite_2p.path_full/'suite2p'/'plane0'/'ops.npy', allow_pickle=True).item()\n",
    "    processed = Path(flz.PARAMETERS['data_root']['processed'])\n",
    "    out = dict(ops=ops)\n",
    "    with open(processed / rec_closeloop.path / 'img_VS.pickle', 'rb') as handle:\n",
    "        out['closedloop'] = pickle.load(handle)\n",
    "    with open(processed / rec_closeloop.path / 'stim_dict.pickle', 'rb') as handle:\n",
    "        out['stim_dict_closedloop'] = pickle.load(handle)\n",
    "    if rec_playback != 'NO PLAYBACK':\n",
    "        with open(processed / rec_playback.path /'img_VS.pickle', 'rb') as handle:\n",
    "            out['playback'] = pickle.load(handle)\n",
    "        with open(processed / rec_playback.path /'stim_dict.pickle', 'rb') as handle:\n",
    "            out['stim_dict_playback'] = pickle.load(handle)\n",
    "    return out\n",
    "\n",
    "recording = flz.get_entity(id=camera.origin_id, flexilims_session=flm_sess)\n",
    "stim_params = get_stim_info(recording)\n",
    "sampling = stim_params['ops']['fs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot time course of eye\n",
    "fig, axes = plt.subplots(4, 1)\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "valid = ellipse.valid\n",
    "time = np.arange(len(dlc_res)) / sampling\n",
    "reflection = dlc_res.xs(axis='columns', level=1, key='reflection')\n",
    "reflection.columns = reflection.columns.droplevel('scorer')\n",
    "for iax, ax in enumerate(axes):\n",
    "    for w in [\"x\", \"y\"]:\n",
    "        if iax > 1:\n",
    "            ax.set_ylabel('Relative to reflection')\n",
    "            d = (ellipse[f'centre_{w}'] - reflection[w])[valid]\n",
    "        else:\n",
    "            ax.set_ylabel('Raw')\n",
    "            d = ellipse[f'centre_{w}'][valid]\n",
    "        ax.plot(time[valid], d-np.nanmedian(d), label=fr\"$\\Delta${w.split('_')[0]}\", lw=1)\n",
    "axes[0].set_xlim(time[0], time[-1])\n",
    "axes[2].set_xlim(time[0], time[-1])\n",
    "for i in [1, 3]:\n",
    "    axes[i].set_xlim(3000, 3000 + 60 * 2)\n",
    "    axes[i].set_ylim(-15, 15)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Time (s)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = analeyesis.add_behaviour(camera, dlc_res, ellipse, speed_threshold=0.01, log_speeds=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(len(data)) / sampling\n",
    "xl = [3000, 3030]\n",
    "xi = time.searchsorted(xl)\n",
    "p = slice(*xi)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(time[p], data.mvt[p])\n",
    "plt.ylabel('Eye movement')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(time[p], data.mvt[p])\n",
    "plt.ylabel('Eye movement')\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[~np.isnan(data.mvt)].mvt\n",
    "sns.displot(d[d>0], log_scale=True)\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Eye movement (pixels between 2 frames)')\n",
    "ax.axvline(3, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "\n",
    "depth_list = np.unique(data.depth)\n",
    "cmap = cm.cool.reversed()\n",
    "line_colors = []\n",
    "norm = mpl.colors.Normalize(vmin=np.log(min(depth_list)), vmax=np.log(max(depth_list)))\n",
    "col_dict = dict()\n",
    "for depth in depth_list:\n",
    "    rgba_color = cmap(norm(np.log(depth)),bytes=True)\n",
    "    rgba_color = tuple(it/255 for it in rgba_color)\n",
    "    line_colors.append(rgba_color)\n",
    "    col_dict[depth] = rgba_color\n",
    "\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "fig.set_size_inches(6, 10)\n",
    "labels = ['X position', 'Y position', 'Distance to median position']\n",
    "d = data[(~np.isnan(data.dx))& (~np.isnan(data.depth))]\n",
    "for iw, w in enumerate(['dx', \"dy\", \"d_med\"]):\n",
    "    \n",
    "    sns.violinplot(data=d, x='depth', y=w, palette=line_colors, ax=axes[iw])\n",
    "    axes[iw].set_ylabel(labels[iw])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "\n",
    "depth_list = np.unique(data.depth)\n",
    "cmap = cm.cool.reversed()\n",
    "line_colors = []\n",
    "norm = mpl.colors.Normalize(vmin=np.log(min(depth_list)), vmax=np.log(max(depth_list)))\n",
    "col_dict = dict()\n",
    "for depth in depth_list:\n",
    "    rgba_color = cmap(norm(np.log(depth)),bytes=True)\n",
    "    rgba_color = tuple(it/255 for it in rgba_color)\n",
    "    line_colors.append(rgba_color)\n",
    "    col_dict[depth] = rgba_color\n",
    "\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "fig.set_size_inches(5, 7)\n",
    "labels = ['Motion', 'Small movements', 'Saccades']\n",
    "data['saccade'] = data.mvt > 5\n",
    "d = data[(~np.isnan(data.dx))& (~np.isnan(data.depth))]\n",
    "for iw in range(2):\n",
    "    if not iw:\n",
    "        sns.violinplot(data=d, x='depth', y='mvt', palette=line_colors, ax=axes[iw])\n",
    "    else:\n",
    "        sns.violinplot(data=d[d.mvt<2], x='depth', y='mvt', palette=line_colors, ax=axes[iw])\n",
    "    axes[iw].set_ylabel(labels[iw])\n",
    "\n",
    "sac_per_depth = d.groupby('depth').saccade.aggregate(np.nansum)\n",
    "sample_per_depth = d.groupby('depth').saccade.aggregate(len)\n",
    "\n",
    "axes[2].bar(x=np.arange(len(sac_per_depth)), height=sac_per_depth/sample_per_depth * sampling, color=line_colors)\n",
    "axes[2].set_xticks(np.arange(len(sac_per_depth)))\n",
    "axes[2].set_xticklabels(sac_per_depth.index)\n",
    "axes[2].set_ylabel('Saccades per second')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "lr = np.log10(data.rs)\n",
    "data['running_bin'] = np.round(data.rs/10) * 10\n",
    "\n",
    "running_bins = np.unique(data[data.valid]['running_bin'])\n",
    "cmap = cm.viridis\n",
    "rs_colors = []\n",
    "norm = mpl.colors.Normalize(vmin=min(running_bins), vmax=max(running_bins))\n",
    "for rb in running_bins:\n",
    "    rgba_color = cmap(norm(rb),bytes=True)\n",
    "    rgba_color = tuple(it/255 for it in rgba_color)\n",
    "    rs_colors.append(rgba_color)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "fig.set_size_inches(5, 7)\n",
    "labels = ['Motion', 'Small movements', 'Saccades']\n",
    "data['saccade'] = data.mvt > 5\n",
    "d = data[(~np.isnan(data.dx))& (~np.isnan(data.depth))]\n",
    "for iw in range(2):\n",
    "    if not iw:\n",
    "        sns.violinplot(data=d, x='running_bin', y='mvt', palette='viridis', ax=axes[iw])\n",
    "    else:\n",
    "        sns.violinplot(data=d[d.mvt<2], x='running_bin', y='mvt', palette='viridis', ax=axes[iw])\n",
    "    axes[iw].set_ylabel(labels[iw])\n",
    "\n",
    "sac_per_depth = d.groupby('running_bin').saccade.aggregate(np.nansum)\n",
    "sample_per_depth = d.groupby('running_bin').saccade.aggregate(len)\n",
    "\n",
    "axes[2].bar(x=np.arange(len(sac_per_depth)), height=sac_per_depth/sample_per_depth * sampling, color=rs_colors)\n",
    "axes[2].set_xticks(np.arange(len(sac_per_depth)))\n",
    "axes[2].set_xticklabels(np.array(sac_per_depth.index, dtype=int))\n",
    "axes[2].set_ylabel('Saccades per second')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "depth_list = np.unique(d.depth)\n",
    "props = ['dx', \"dy\", \"d_med\"]\n",
    "pval_mat = np.zeros([len(props)] + [len(depth_list)]*2)\n",
    "\n",
    "for ix, dx in enumerate(depth_list):\n",
    "    xdf = d[d.depth == dx]\n",
    "    for iy, dy in enumerate(depth_list):\n",
    "        for ip, p in enumerate(props):\n",
    "            ydf = d[d.depth == dy]\n",
    "            if ix == iy:\n",
    "                pval_mat[ip, ix, iy] = 0\n",
    "            else:\n",
    "                w = mannwhitneyu(xdf[p].values, ydf[p].values)\n",
    "                pval_mat[ip, ix, iy] = w.pvalue\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "for ip, p in enumerate(props):\n",
    "    axes[ip].imshow(pval_mat[ip] - 0.05, cmap='RdBu', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "for d, ddf in data.groupby('depth'):\n",
    "    axes[0].errorbar(x=np.nanmedian(ddf.dx), y=np.nanmedian(ddf.dy), xerr=np.nanstd(ddf.dx), yerr=np.nanstd(ddf.dy), label=int(d), marker='o', color=col_dict[d])\n",
    "    axes[1].errorbar(x=np.nanmean(ddf.dx), y=np.nanmean(ddf.dy), \n",
    "                xerr=np.nanstd(ddf.dx)/np.sqrt(np.sum(~np.isnan(ddf.dx))), \n",
    "                yerr=np.nanstd(ddf.dy)/np.sqrt(np.sum(~np.isnan(ddf.dy))), label=int(d), marker='.', lw=3,\n",
    "                color=col_dict[d])\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "axes[0].set_title('Eye position (median +/- std)')\n",
    "axes[1].set_title('Eye position (mean +/- std)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_VS = pd.merge_asof(\n",
    "    img_VS,\n",
    "    mousez_logger,\n",
    "    on=\"HarpTime\",\n",
    "    allow_exact_matches=True,\n",
    "    direction=\"backward\",\n",
    ")\n",
    "\n",
    "img_VS.EyeZ = img_VS.EyeZ / 100  # Convert cm to m\n",
    "img_VS.MouseZ = img_VS.MouseZ / 100  # Convert cm to m\n",
    "img_VS.Depth = img_VS.Depth / 100  # Convert cm to m\n",
    "img_VS.Z0 = img_VS.Z0 / 100  # Convert cm to m\n",
    "\n",
    "depth_list = img_VS[\"Depth\"].unique()\n",
    "depth_list = np.round(depth_list, 2)\n",
    "depth_list = depth_list[~np.isnan(depth_list)].tolist()\n",
    "depth_list.remove(-99.99)\n",
    "depth_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# print(img_VS[:20], flush=True)\n",
    "# Save img_VS\n",
    "with open(protocol_folder / \"img_VS.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(img_VS, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Timestamps aligned and saved.\", flush=True)\n",
    "print(\"---STEP 3 FINISHED.---\", \"\\n\", flush=True)\n",
    "\n",
    "# -----STEP4: Get the visual stimulation structure and Save (find the imaging frames for visual stimulation)-----\n",
    "print(\"---START STEP 4---\", \"\\n\", \"Get vis-stim structure...\", flush=True)\n",
    "with open(protocol_folder / \"img_VS.pickle\", \"rb\") as handle:\n",
    "    img_VS = pickle.load(handle)\n",
    "from cottage_analysis.stimulus_structure import sphere_structure as vis_stim_structure\n",
    "stim_dict = vis_stim_structure.create_stim_dict(\n",
    "    depth_list=depth_list, img_VS=img_VS, choose_trials=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_VS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_VS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_res.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cottage_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "272882de78d91b881035f683a12ffa07edc574ccc635c980b383a6ea3db59afc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
