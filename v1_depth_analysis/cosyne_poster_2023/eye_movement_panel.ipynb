{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Eye movement panel of the poster\n",
    "\n",
    "Looks only at right eye cameras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/camp/home/hey2/.conda/envs/cottage_eye/lib/python3.9/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# from skimage.measure import EllipseModel\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import flexiznam as flz\n",
    "from v1_depth_analysis.config import PROJECT\n",
    "import v1_depth_analysis as vda\n",
    "from cottage_analysis.eye_tracking import analysis as analeyesis\n",
    "from cottage_analysis.eye_tracking import eye_model_fitting as emf\n",
    "\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42  # save text as text not outlines\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "MOTION_CUTOFF = 0  # in degrees\n",
    "VERSION = 1\n",
    "\n",
    "save_root = Path(\n",
    "    f\"/camp/lab/znamenskiyp/home/shared/presentations/Cosyne2023/ver{VERSION}/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/camp/home/hey2/.conda/envs/cottage_eye/lib/python3.9/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas._libs.lib' has no attribute 'clean_index_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-093569052596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflm_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flexilims_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrecordings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recordings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SpheresPermTubeReward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflm_sess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflm_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m datasets = vda.get_datasets(\n\u001b[1;32m      8\u001b[0m     \u001b[0mrecordings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"camera\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name_contains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_eye\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflm_sess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflm_sess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nemo/lab/znamenskiyp/home/users/hey2/codes/3d-vision-analysis-2p/v1_depth_analysis/utils.py\u001b[0m in \u001b[0;36mget_recordings\u001b[0;34m(protocol, sessions, flm_sess)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msessions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sessions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflm_sess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflm_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mrecordings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nemo/lab/znamenskiyp/home/users/hey2/codes/3d-vision-analysis-2p/v1_depth_analysis/utils.py\u001b[0m in \u001b[0;36mget_sessions\u001b[0;34m(flm_sess)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msession_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmouse_folder\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"S20{session}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0msession_folder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             sess = flm.get_entity(\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{mouse}_S20{session}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflexilims_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflm_sess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/flexiznam/main.py\u001b[0m in \u001b[0;36mget_entity\u001b[0;34m(datatype, query_key, query_value, project_id, flexilims_session, name, origin_id, id, format_reply)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"mouse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"session\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recording\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m             \u001b[0mentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_entity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/flexiznam/main.py\u001b[0m in \u001b[0;36mget_entity\u001b[0;34m(datatype, query_key, query_value, project_id, flexilims_session, name, origin_id, id, format_reply)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     entity = get_entities(\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mquery_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/flexiznam/main.py\u001b[0m in \u001b[0;36mget_entities\u001b[0;34m(datatype, query_key, query_value, project_id, flexilims_session, name, origin_id, id, format_reply)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/flexiznam/main.py\u001b[0m in \u001b[0;36mformat_results\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attributes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;31m# set the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5894\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5896\u001b[0;31m         \u001b[0mconverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_index_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall_arrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas._libs.lib' has no attribute 'clean_index_list'"
     ]
    }
   ],
   "source": [
    "# get session list\n",
    "raw_path = Path(flz.PARAMETERS[\"data_root\"][\"raw\"])\n",
    "processed_path = Path(flz.PARAMETERS[\"data_root\"][\"processed\"])\n",
    "flm_sess = flz.get_flexilims_session(project_id=PROJECT)\n",
    "\n",
    "recordings = vda.get_recordings(protocol=\"SpheresPermTubeReward\", flm_sess=flm_sess)\n",
    "datasets = vda.get_datasets(\n",
    "    recordings, dataset_type=\"camera\", dataset_name_contains=\"_eye\", flm_sess=flm_sess\n",
    ")\n",
    "# keep only right eye cameras\n",
    "datasets = [ds for ds in datasets if \"right\" in ds.dataset_name]\n",
    "camera_datasets = {ds.full_name: ds for ds in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/camp/home/hey2/.conda/envs/cottage_eye/lib/python3.9/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas._libs.lib' has no attribute 'clean_index_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f7a88185ab94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mno_behaviour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcamera_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     dlc_res, ellipse = analeyesis.get_data(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mcamera\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mflexilims_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflm_sess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nemo/lab/znamenskiyp/home/users/hey2/codes/cottage_analysis/cottage_analysis/eye_tracking/analysis.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(camera, flexilims_session, likelihood_threshold, rsquare_threshold, error_threshold)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \"\"\"\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     rec_ds = flz.get_children(\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mparent_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mflexilims_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflexilims_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/flexiznam/main.py\u001b[0m in \u001b[0;36mget_children\u001b[0;34m(parent_id, children_datatype, project_id, flexilims_session)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflexilims_session\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mflexilims_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_flexilims_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflexilims_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/flexiznam/main.py\u001b[0m in \u001b[0;36mformat_results\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attributes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;31m# set the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cottage_eye/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5894\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5896\u001b[0;31m         \u001b[0mconverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_index_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall_arrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas._libs.lib' has no attribute 'clean_index_list'"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "data_by_recording = dict()\n",
    "sampling_by_recording = dict()\n",
    "no_behaviour = []\n",
    "for cam_name, camera in camera_datasets.items():\n",
    "    dlc_res, ellipse = analeyesis.get_data(\n",
    "        camera,\n",
    "        flexilims_session=flm_sess,\n",
    "        likelihood_threshold=0.88,\n",
    "        rsquare_threshold=0.99,\n",
    "        error_threshold=3,\n",
    "    )\n",
    "    try:\n",
    "        data, sampling = analeyesis.add_behaviour(\n",
    "            camera,\n",
    "            dlc_res,\n",
    "            ellipse,\n",
    "            speed_threshold=0.01,\n",
    "            log_speeds=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "    except FileNotFoundError as err:\n",
    "        warnings.warn(f\"No data for {cam_name}\")\n",
    "        no_behaviour.append(cam_name)\n",
    "    assert \"valid\" in data.columns\n",
    "    # add trial number\n",
    "    depth = np.array(data.depth.values, copy=True)\n",
    "    depth[np.isnan(depth)] = -9999\n",
    "    depth = np.round(depth, 2)\n",
    "    trials_border = np.diff(np.hstack([-9999, depth]))\n",
    "    trials_onset = np.where(trials_border > 5000)[0]\n",
    "    trials_offset = np.where(trials_border < -5000)[0]\n",
    "    trial_id = np.zeros(depth.shape) + np.nan\n",
    "    for itrial, (on, off) in enumerate(zip(trials_onset, trials_offset)):\n",
    "        trial_id[on:off] = itrial\n",
    "    data[\"trial_id\"] = trial_id\n",
    "    data_by_recording[cam_name] = data\n",
    "    sampling_by_recording[cam_name] = sampling\n",
    "print(f\"Loaded {len(data_by_recording)- len(no_behaviour)}/{len(datasets)} recordings \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the eye tracking fit\n",
    "eye_parameters_by_recording = dict()\n",
    "eye_rotations_by_recording = dict()\n",
    "no_tracking = []\n",
    "for cam_name, camera in camera_datasets.items():\n",
    "    camera_save_folder = processed_path / camera.path / camera.dataset_name\n",
    "    try:\n",
    "        eye_parameters_by_recording[cam_name] = np.load(\n",
    "            camera_save_folder / f\"{camera.dataset_name}_eye_parameters.npz\"\n",
    "        )\n",
    "    except FileNotFoundError as err:\n",
    "        warnings.warn(f\"No data for {cam_name}\")\n",
    "        no_tracking.append(cam_name)\n",
    "        continue\n",
    "    eye_rotations_by_recording[cam_name] = np.load(\n",
    "        camera_save_folder / f\"{camera.dataset_name}_eye_rotation_by_frame.npy\"\n",
    "    )\n",
    "print(f\"Loaded {len(eye_rotations_by_recording)}/{len(datasets)} recordings \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get camera extrinsics\n",
    "calibration_folder = processed_path / PROJECT / \"Calibrations\"\n",
    "calib_data = dict()\n",
    "for cam_name in [\"RightEyeCam\", \"LeftEyeCam\"]:\n",
    "    calib_data[cam_name.lower()] = dict()\n",
    "    folder = calibration_folder / cam_name\n",
    "    folder = list(folder.glob(\"*xtrinsics_flat\"))[0]  # case is inconsistent\n",
    "    folder = folder / \"20220818\" / \"aruco5_5mm\"\n",
    "    assert folder.exists()\n",
    "    for trial in folder.glob(\"trial*\"):\n",
    "        fname = str(trial / \"camera_extrinsics_flat.yml\")\n",
    "        s = cv2.FileStorage()\n",
    "        s.open(fname, cv2.FileStorage_READ)\n",
    "        rvec = s.getNode(\"rvec\").mat()\n",
    "        tvec = s.getNode(\"tvec\").mat()\n",
    "        calib_data[cam_name.lower()][trial.name] = dict(rvec=rvec, tvec=tvec)\n",
    "# take median across trials\n",
    "extrinsics = dict()\n",
    "for cam, trials in calib_data.items():\n",
    "    extrinsics[cam] = dict()\n",
    "    for w in [\"rvec\", \"tvec\"]:\n",
    "        extrinsics[cam][w] = np.median(\n",
    "            np.vstack([d[w].flatten() for d in trials.values()]), axis=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get azimuth elevation\n",
    "azel_by_recording = dict()\n",
    "bad_number = []\n",
    "valid_data = dict()\n",
    "for cam_name, eye_rotation in eye_rotations_by_recording.items():\n",
    "    if cam_name not in data_by_recording:\n",
    "        print(f\"Skipping bad session {cam_name}\")\n",
    "    camera = camera_datasets[cam_name]\n",
    "    # get the camera we need for this acq and build tform matrix\n",
    "    extrin = extrinsics[camera.dataset_name.replace(\"_\", \"\")[:-3]]\n",
    "    rmat, jac = cv2.Rodrigues(extrin[\"rvec\"])\n",
    "    gaze_vec = np.vstack([emf.get_gaze_vector(p[0], p[1]) for p in eye_rotation])\n",
    "    world_gaze = emf.convert_to_world(gaze_vec, rmat=rmat)\n",
    "    azimuth, elevation = emf.gaze_to_azel(world_gaze)\n",
    "\n",
    "    # add that to dataframe\n",
    "    # I need to cut the last few because of extra SI triggers\n",
    "\n",
    "    azel_by_recording = np.vstack([azimuth, elevation])\n",
    "    n = len(data_by_recording[cam_name])\n",
    "    difference = len(azimuth) - n\n",
    "    if (difference < 0) or (difference > 5):\n",
    "        bad_number.append([cam_name, difference])\n",
    "    else:\n",
    "        valid_data[cam_name] = data_by_recording[cam_name].copy()\n",
    "        valid_data[cam_name][\"azimuth\"] = np.rad2deg(\n",
    "            azimuth[:n] - np.nanmedian(azimuth[:n])\n",
    "        )\n",
    "        valid_data[cam_name][\"elevation\"] = np.rad2deg(\n",
    "            elevation[:n] - np.nanmedian(elevation[:n])\n",
    "        )\n",
    "print(f\"Got {len(valid_data)} recordings at the end\")\n",
    "bad_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some useful measure\n",
    "for cam_name, data in valid_data.items():\n",
    "    data[\"delta_az\"] = data.azimuth.diff()\n",
    "    data[\"temporonasal_direction\"] = np.sign(data.delta_az)\n",
    "    data[\"delta_el\"] = data.elevation.diff()\n",
    "    data[\"nasal\"] = np.nan\n",
    "    data[\"temporal\"] = np.nan\n",
    "    data.loc[data.delta_az > 0, \"nasal\"] = np.abs(\n",
    "        data.loc[data.delta_az > MOTION_CUTOFF, \"delta_az\"]\n",
    "    )\n",
    "    data.loc[data.delta_az < 0, \"temporal\"] = np.abs(\n",
    "        data.loc[data.delta_az < -MOTION_CUTOFF, \"delta_az\"]\n",
    "    )\n",
    "    data[\"angle_of_motion\"] = np.rad2deg(\n",
    "        np.arctan2(np.deg2rad(data.delta_el), np.deg2rad(data.delta_az))\n",
    "    )\n",
    "    data[\"amplitude_of_motion\"] = np.linalg.norm(\n",
    "        np.vstack([data.delta_az, data.delta_el]), axis=0\n",
    "    )\n",
    "    data[\"angle_when_moving\"] = np.nan\n",
    "    data[\"saccade\"] = data[\"amplitude_of_motion\"] > (80 / sampling)\n",
    "    data[\"saccade_direction\"] = data.saccade * data.temporonasal_direction\n",
    "    data[\"slow_motion\"] = data.amplitude_of_motion.copy()\n",
    "    data.loc[data.slow_motion > (80 / sampling), \"slow_motion\"] = np.nan\n",
    "    moving = data.amplitude_of_motion > MOTION_CUTOFF\n",
    "    data.loc[moving, \"angle_when_moving\"] = data.loc[moving, \"amplitude_of_motion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove session where the fit failed\n",
    "badly_fitted = \"PZAH6.4b_S20220519_R183410_SpheresPermTubeReward_right_eye_camera\"\n",
    "_ = valid_data.pop(badly_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data by session\n",
    "\n",
    "by_session = []\n",
    "av_trials = False\n",
    "for cam_name, data in valid_data.items():\n",
    "    in_corridor = data[~np.isnan(data.depth)].copy()\n",
    "    by_trial = in_corridor.groupby([\"trial_id\"])\n",
    "    m_by_trial = by_trial.aggregate(np.nanmean)\n",
    "    if av_trials:\n",
    "        # now average trial averages\n",
    "        m_by_depth = m_by_trial.groupby([\"depth\"]).aggregate(np.nanmean)\n",
    "    else:\n",
    "        m_by_depth = m_by_trial\n",
    "    m_by_depth = m_by_depth.reset_index()\n",
    "    m_by_depth[\"session\"] = cam_name\n",
    "    by_session.append(m_by_depth)\n",
    "\n",
    "by_session = pd.concat(by_session, ignore_index=True)\n",
    "by_session.shape\n",
    "\n",
    "# add cumulative motion\n",
    "cumul_session = []\n",
    "for cam_name, data in valid_data.items():\n",
    "    in_corridor = data[~np.isnan(data.depth)].copy()\n",
    "    by_trial = in_corridor.groupby([\"trial_id\"])\n",
    "    m_by_trial = by_trial.aggregate(np.nansum)\n",
    "    if av_trials:\n",
    "        # now average trial averages\n",
    "        m_by_depth = m_by_trial.groupby([\"depth\"]).aggregate(np.nanmean)\n",
    "    else:\n",
    "        m_by_depth = m_by_trial\n",
    "    m_by_depth = m_by_depth.reset_index()\n",
    "    m_by_depth[\"session\"] = cam_name\n",
    "    cumul_session.append(m_by_depth)\n",
    "by_session_cumul = pd.concat(cumul_session, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get example session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_full_name = \"PZAH6.4b_S20220419_R145152_SpheresPermTubeReward_right_eye_camera\"\n",
    "start_frame = 22000\n",
    "\n",
    "camera_full_name = \"PZAH6.4b_S20220512_R190248_SpheresPermTubeReward_right_eye_camera\"\n",
    "\n",
    "camera = [ds for ds in datasets if ds.full_name == camera_full_name]\n",
    "camera = camera[0]\n",
    "print(f\"Analysing {' from '.join(camera.genealogy[::-1])}\")\n",
    "data = valid_data[camera_full_name]\n",
    "eye_parameters = eye_parameters_by_recording[camera_full_name]\n",
    "eye_rotations = eye_rotations_by_recording[camera_full_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get example frame\n",
    "video_file = camera.path_full / camera.extra_attributes[\"video_file\"]\n",
    "dlc_ds_name = \"_\".join(\n",
    "    list(camera.genealogy[:-1]) + [\"dlc_tracking\", camera.dataset_name, \"data\", \"0\"]\n",
    ")\n",
    "dlc_ds = flz.Dataset.from_flexilims(name=dlc_ds_name, flexilims_session=flm_sess)\n",
    "cropping = dlc_ds.extra_attributes[\"cropping\"]\n",
    "cam_data = cv2.VideoCapture(str(video_file))\n",
    "cam_data.set(cv2.CAP_PROP_POS_FRAMES, start_frame - 1)\n",
    "ret, frame = cam_data.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "cam_data.release()\n",
    "gray = gray[cropping[2] : cropping[3], cropping[0] : cropping[1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example eye\n",
    "\n",
    "## binned data\n",
    "elli = pd.DataFrame(data[data.valid], copy=True)\n",
    "count, bin_edges_x, bin_edges_y = np.histogram2d(\n",
    "    elli.pupil_x, elli.pupil_y, bins=(25, 25)\n",
    ")\n",
    "elli[\"bin_id_x\"] = bin_edges_x.searchsorted(elli.pupil_x.values)\n",
    "elli[\"bin_id_y\"] = bin_edges_y.searchsorted(elli.pupil_y.values)\n",
    "binned_ellipses = elli.groupby([\"bin_id_x\", \"bin_id_y\"])\n",
    "ns = binned_ellipses.valid.aggregate(len)\n",
    "binned_ellipses = binned_ellipses.aggregate(np.nanmedian)\n",
    "mat = np.zeros((26, 26, 2)) + np.nan\n",
    "for i_pos, (pos, series) in enumerate(binned_ellipses.iterrows()):\n",
    "    mat[pos[1], pos[0]] = series[[\"azimuth\", \"elevation\"]].values\n",
    "\n",
    "# get other things we want to plot\n",
    "eye_centre = eye_parameters[\"eye_centre\"]\n",
    "f_z0 = eye_parameters[\"f_z0\"]\n",
    "ellipse_model = emf.reproj_ellipse(\n",
    "    *eye_rotations[start_frame], eye_centre=eye_centre, f_z0=f_z0\n",
    ")\n",
    "ref = data.iloc[start_frame][[\"reflection_x\", \"reflection_y\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get depth color\n",
    "depth_list = np.unique(data.depth)\n",
    "depth_list = depth_list[~np.isnan(depth_list)]\n",
    "cmap = mpl.cm.cool.reversed()\n",
    "line_colors = []\n",
    "norm = mpl.colors.Normalize(vmin=np.log(min(depth_list)), vmax=np.log(max(depth_list)))\n",
    "col_dict = dict()\n",
    "for depth in depth_list:\n",
    "    rgba_color = cmap(norm(np.log(depth)), bytes=True)\n",
    "    rgba_color = tuple(it / 255 for it in rgba_color)\n",
    "    line_colors.append(rgba_color)\n",
    "    col_dict[depth] = rgba_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_eye(ax, fig):\n",
    "    v = binned_ellipses[[\"pupil_x\", \"pupil_y\"]].values\n",
    "    lims = np.vstack([np.nanmin(v, axis=0), np.nanmax(v, axis=0)]) + ref\n",
    "    circ_coord = ellipse_model.predict_xy(np.arange(0, 2 * np.pi, 0.1)) + ref.reshape(\n",
    "        1, 2\n",
    "    )\n",
    "    vmin, vmax = np.quantile(gray, [0.01, 0.8])\n",
    "    ax.imshow(gray, cmap=\"gray\", vmin=vmin, vmax=vmax, zorder=-1)\n",
    "    img = ax.imshow(\n",
    "        mat[..., 0],\n",
    "        extent=np.hstack([lims[:, 0], lims[::-1, 1]]),\n",
    "        cmap=\"RdBu_r\",\n",
    "        vmin=-20,\n",
    "        vmax=20,\n",
    "        zorder=10,\n",
    "    )\n",
    "    ax.plot(\n",
    "        circ_coord[:, 0],\n",
    "        circ_coord[:, 1],\n",
    "        label=\"Reprojection\",\n",
    "        color=\"lightblue\",\n",
    "        alpha=0.5,\n",
    "        zorder=5,\n",
    "    )\n",
    "    pupil_c = np.array(ellipse_model.params[:2])\n",
    "    ax.plot(*(eye_centre + ref), marker=\"o\", ms=5, mfc=\"k\", mec=\"none\", zorder=1)\n",
    "    ax.plot(\n",
    "        *(pupil_c + ref), marker=\"o\", ms=5, mfc=\"none\", color=\"lightblue\", alpha=0.5\n",
    "    )\n",
    "    ax.plot(\n",
    "        *[(np.array([eye_centre[i], pupil_c[i]]) + ref[i]) for i in range(2)],\n",
    "        color=\"lightblue\",\n",
    "        zorder=2,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cb = fig.colorbar(img, cax=cax)\n",
    "    cb.set_label(\"Azimuth (degrees)\")\n",
    "    ax.set_xlim([gray.shape[1], 0])\n",
    "    ax.set_ylim([gray.shape[0] - 80, 50])\n",
    "    ax.text(x=0.5, y=0.8, s=\"Dorsal\", color=\"white\", transform=ax.transAxes)\n",
    "    ax.text(x=0.6, y=0.1, s=\"Nasal\", color=\"white\", transform=ax.transAxes)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time course\n",
    "colors = [np.array([141, 160, 203]) / 255, np.array([252, 141, 98]) / 255]\n",
    "\n",
    "\n",
    "def plot_time_course(\n",
    "    ax,\n",
    "    n_samples=int(120 * sampling),\n",
    "    begin=20000,\n",
    "    colors=colors,\n",
    "    add_velocity=True,\n",
    "    vel_by_depth=True,\n",
    "):\n",
    "\n",
    "    ax.axhline(0, color=\"grey\", alpha=0.5, lw=1)\n",
    "    time = np.arange(n_samples) / sampling\n",
    "\n",
    "    azim = data.azimuth\n",
    "    elev = data.elevation\n",
    "    ax.plot(\n",
    "        time, elev[begin : begin + n_samples], color=colors[1], label=\"Elevation\", lw=1\n",
    "    )\n",
    "    ax.plot(\n",
    "        time,\n",
    "        azim[begin : begin + n_samples],\n",
    "        color=colors[0],\n",
    "        label=\"Azimuth\",\n",
    "        lw=1,\n",
    "    )\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(r\"$\\Delta$angle (degrees)\")\n",
    "    ax.set_xlim(0, time.max())\n",
    "    ax.set_ylim(-20, 20)\n",
    "    ax.set_xticks(np.arange(0, time.max(), 60))\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax_h = divider.append_axes(\"right\", size=\"10%\", pad=0.05)\n",
    "    bins = np.arange(-25, 25)\n",
    "    ax_h.spines[\"right\"].set_visible(False)\n",
    "    ax_h.spines[\"top\"].set_visible(False)\n",
    "    ax_h.hist(\n",
    "        elev,\n",
    "        orientation=\"horizontal\",\n",
    "        density=True,\n",
    "        bins=bins,\n",
    "        color=colors[1],\n",
    "        histtype=\"step\",\n",
    "        lw=2,\n",
    "    )\n",
    "    ax_h.hist(\n",
    "        azim,\n",
    "        orientation=\"horizontal\",\n",
    "        density=True,\n",
    "        bins=bins,\n",
    "        color=colors[0],\n",
    "        histtype=\"step\",\n",
    "        lw=2,\n",
    "    )\n",
    "    ax_h.set_xlabel(\"Density\")\n",
    "    ax_h.set_yticks([])\n",
    "    if add_velocity:\n",
    "        ax_v = divider.append_axes(\"top\", size=\"50%\", pad=0.1)\n",
    "        # ax_hv = divider.append_axes(\"top right\", size=\"10%\", pad=0.05, sharey=ax_v)\n",
    "        # ax_hv.spines[\"right\"].set_visible(False)\n",
    "        # ax_hv.spines[\"top\"].set_visible(False)\n",
    "        bins = np.arange(0, 200)\n",
    "\n",
    "        if vel_by_depth:\n",
    "            depth = np.array(data.depth[begin : begin + n_samples])\n",
    "            depth[np.isnan(depth)] = -1\n",
    "            for d in np.unique(depth):\n",
    "                mask = depth == d\n",
    "                data_trace = np.array(\n",
    "                    data.amplitude_of_motion[begin : begin + n_samples]\n",
    "                )\n",
    "                data_trace[~mask] += np.nan\n",
    "                if d == -1:\n",
    "                    color = np.array([0.7, 0.7, 0.7, 1])\n",
    "                else:\n",
    "                    color = line_colors[list(depth_list).index(d)]\n",
    "                ax_v.plot(\n",
    "                    time, data_trace * sampling, color=color, label=\"Velocity\", lw=1\n",
    "                )\n",
    "        else:\n",
    "            ax_v.plot(\n",
    "                time,\n",
    "                data.amplitude_of_motion[begin : begin + n_samples] * sampling,\n",
    "                color=[0.2, 0.2, 0.2],\n",
    "                label=\"Velocity\",\n",
    "                lw=1,\n",
    "            )\n",
    "        ax_v.set_ylim(0, 200)\n",
    "        ax_v.set_ylabel(r\"Velocity ($^{\\circ}.s^{-1}$)\")\n",
    "        ax_v.set_xlim(ax.get_xlim())\n",
    "        ax_v.set_xticks(np.arange(0, time.max(), 60))\n",
    "        ax_v.set_xticklabels([])\n",
    "    datapart = data[begin : begin + n_samples]\n",
    "    for trial in datapart.trial_id.unique():\n",
    "        if np.isnan(trial):\n",
    "            continue\n",
    "        b, e = datapart[datapart.trial_id == trial].index[[0, -1]]\n",
    "        color = line_colors[list(depth_list).index(data.iloc[b].depth)]\n",
    "        if not vel_by_depth:\n",
    "            for x in ax, ax_v:\n",
    "                x.axvspan(\n",
    "                    *((np.array([b, e]) - begin) / sampling),\n",
    "                    color=color,\n",
    "                    zorder=-10,\n",
    "                    alpha=0.5,\n",
    "                    edgecolor=\"None\"\n",
    "                )\n",
    "        else:\n",
    "            for p in [b]:\n",
    "                ax.axvline(\n",
    "                    (p - begin) / sampling, color=color, zorder=-10, alpha=0.5, lw=1\n",
    "                )\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7, 3))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plot_time_course(\n",
    "    ax,\n",
    "    n_samples=int(10 * 60 * sampling),\n",
    "    begin=65000,\n",
    "    add_velocity=True,\n",
    "    colors=np.array([[0.2, 0.2, 0.2], [0.4, 0.4, 0.4]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapart = data[1000:10000]\n",
    "for trial in datapart.trial_id.unique():\n",
    "    if np.isnan(trial):\n",
    "        continue\n",
    "    b, e = datapart[datapart.trial_id == trial].index[[0, -1]]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "\n",
    "def label_violins(ax, title=None, hue_order=[\"nasal\", \"temporal\"]):\n",
    "    idepth = 0\n",
    "    handles = []\n",
    "    for ind, violin in enumerate(ax.findobj(PolyCollection)):\n",
    "        color = line_colors[idepth]\n",
    "        if ind % 2 != 0:\n",
    "            color = 0.5 + 0.5 * np.array(color)  # make whiter\n",
    "            idepth += 1\n",
    "        violin.set_facecolor(color)\n",
    "        handles.append(plt.Rectangle((0, 0), 0, 0, facecolor=color, edgecolor=\"black\"))\n",
    "    ax.legend(\n",
    "        handles=[tuple(handles[::2]), tuple(handles[1::2])],\n",
    "        labels=hue_order,\n",
    "        title=title,\n",
    "        handlelength=4,\n",
    "        handler_map={tuple: HandlerTuple(ndivide=None, pad=0)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_dataframe = []\n",
    "for cam, cam_data in valid_data.items():\n",
    "    cam_data[\"recording\"] = cam\n",
    "    cam_data[\"mouse\"] = cam.split(\"_\")[0]\n",
    "    fused_dataframe.append(cam_data)\n",
    "fused_dataframe = pd.concat(fused_dataframe, ignore_index=True)\n",
    "for col in fused_dataframe.columns:\n",
    "    try:\n",
    "        fused_dataframe[col] = fused_dataframe[col].astype(float)\n",
    "    except ValueError:\n",
    "        print(f\"Not changing {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.axvline(1, color=\"k\")\n",
    "_ = plt.hist(fused_dataframe.running_speed, bins=np.arange(0, 200))\n",
    "\n",
    "np.save(save_root / \"all_running_speeds.npy\", fused_dataframe.running_speed.values)\n",
    "plt.subplot(1, 2, 2)\n",
    "_ = plt.hist(\n",
    "    np.log10(fused_dataframe.running_speed[fused_dataframe.running_speed > 1].values),\n",
    "    bins=np.arange(0, 3, 0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17.7165, 7.87402), constrained_layout=False)\n",
    "# Eye tracking video example\n",
    "ax = plt.subplot2grid((4, 12), (0, 0), rowspan=2, colspan=2)\n",
    "plot_example_eye(ax, fig)\n",
    "\n",
    "ax_timecourse = plt.subplot2grid((4, 12), (0, 3), rowspan=2, colspan=4)\n",
    "plot_time_course(\n",
    "    ax_timecourse,\n",
    "    n_samples=int(10 * 60 * sampling),\n",
    "    begin=65000,\n",
    "    add_velocity=True,\n",
    "    colors=np.array([[0.2, 0.2, 0.2], [0.4, 0.4, 0.4]]),\n",
    ")\n",
    "ax_timecourse.set_ylim([-21, 21])\n",
    "# plot of position by depth\n",
    "ax_medposition = plt.subplot2grid((4, 12), (0, 7), rowspan=2, colspan=2)\n",
    "\n",
    "in_corridor = data[~np.isnan(data.depth)]\n",
    "by_trial = in_corridor.groupby([\"trial_id\"])\n",
    "m_by_trial = by_trial.aggregate(np.nanmean)\n",
    "by_depth = m_by_trial.reset_index().groupby(\"depth\")\n",
    "\n",
    "m_by_depth = by_depth.aggregate(np.nanmean)\n",
    "std_by_depth = by_depth.aggregate(np.nanstd)\n",
    "for idepth, depth in enumerate(depth_list):\n",
    "    ax_medposition.errorbar(\n",
    "        m_by_depth.loc[depth].azimuth,\n",
    "        m_by_depth.loc[depth].elevation,\n",
    "        xerr=std_by_depth.loc[depth].azimuth,\n",
    "        yerr=std_by_depth.loc[depth].elevation,\n",
    "        marker=\"o\",\n",
    "        color=line_colors[idepth],\n",
    "        label=int(depth),\n",
    "    )\n",
    "# ax_medposition.legend(loc=\"upper right\", ncol=2)\n",
    "ax_medposition.set_xlabel(r\"Azimuth ($\\circ$)\")\n",
    "ax_medposition.set_xlim([-5, 5])\n",
    "ax_medposition.set_ylim([-5, 5])\n",
    "ax_medposition.set_ylabel(r\"Elevation ($\\circ$)\")\n",
    "\n",
    "\n",
    "ax_sacc = plt.subplot2grid((4, 12), (0, 9), rowspan=2, colspan=2)\n",
    "what2plot = \"amplitude_of_motion\"\n",
    "factor = sampling\n",
    "bins = np.linspace(0, np.nanmax(data[what2plot] * factor), 30)\n",
    "obj = sns.histplot(\n",
    "    ax=ax_sacc,\n",
    "    x=data[what2plot] * factor,\n",
    "    hue=data.depth,\n",
    "    palette=line_colors,\n",
    "    bins=bins,\n",
    "    element=\"step\",\n",
    "    fill=False,\n",
    ")\n",
    "ax_sacc.semilogy()\n",
    "ax_sacc.set_xlim([0, bins.max()])\n",
    "ax_sacc.set_xlabel(r\"Eye velocity ($^\\circ.s^{-1}$)\")\n",
    "sns.move_legend(obj, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "if False:\n",
    "    # give up on the polar plots\n",
    "    ax_pos = [(0, 9), (0, 10), (1, 9), (1, 10), (1, 11)]\n",
    "    width = 20\n",
    "    bins = np.arange(-180, 180, width)\n",
    "\n",
    "    for idepth, depth in enumerate(depth_list):\n",
    "        ax_polar = plt.subplot2grid(\n",
    "            (5, 12), ax_pos[idepth], rowspan=1, colspan=1, projection=\"polar\"\n",
    "        )\n",
    "        d = data.loc[data.depth == depth]\n",
    "        h, _ = np.histogram(\n",
    "            d[d.amplitude_of_motion > (80 / sampling)].angle_of_motion, bins=bins\n",
    "        )\n",
    "        ax_polar.bar(\n",
    "            np.deg2rad(bins[:-1]), h, width=np.deg2rad(width), color=line_colors[idepth]\n",
    "        )\n",
    "        ax_polar.set_rlim(0, 14)\n",
    "        ax_polar.grid(False)\n",
    "        ax_polar.set_xticks([])\n",
    "        ax_polar.set_yticks([])\n",
    "\n",
    "    ax_polar.set_xticks(np.arange(0, np.pi, np.pi / 2))\n",
    "    ax_polar.set_xticklabels([\"Nasal\", \"Dorsal\"])\n",
    "    ax_polar.set_yticks([14])\n",
    "\n",
    "ax_all_sess = plt.subplot2grid((4, 12), (2, 0), rowspan=2, colspan=3)\n",
    "azel_df = pd.DataFrame(\n",
    "    dict(\n",
    "        Axis=[\"Azimuth\"] * len(by_session) + [\"Elevation\"] * len(by_session),\n",
    "        Position=np.hstack([by_session.azimuth.values, by_session.elevation.values]),\n",
    "        Depth=np.hstack([by_session.depth, by_session.depth]).astype(int),\n",
    "    )\n",
    ")\n",
    "ax_all_sess.axhline(0, color=\"gray\", alpha=0.5, zorder=-10)\n",
    "sns.violinplot(\n",
    "    azel_df,\n",
    "    x=\"Depth\",\n",
    "    y=\"Position\",\n",
    "    hue=\"Axis\",\n",
    "    ax=ax_all_sess,\n",
    "    split=True,\n",
    "    hue_order=[\"Azimuth\", \"Elevation\"],\n",
    ")\n",
    "label_violins(ax_all_sess, title=None, hue_order=[\"Azimuth\", \"Elevation\"])\n",
    "ax_all_sess.set_xlabel(\"Depth\")\n",
    "ax_all_sess.set_ylabel(r\"Average eye position ($^\\circ$)\")\n",
    "\n",
    "ax_all_sess = plt.subplot2grid((4, 12), (2, 3), rowspan=2, colspan=3)\n",
    "if False:\n",
    "    azel_df = pd.DataFrame(\n",
    "        dict(\n",
    "            Axis=[\"Nasal\"] * len(by_session) + [\"Temporal\"] * len(by_session),\n",
    "            Speed=np.hstack(\n",
    "                [\n",
    "                    by_session.nasal.values * sampling,\n",
    "                    by_session.temporal.values * sampling,\n",
    "                ]\n",
    "            ),\n",
    "            Depth=np.hstack([by_session.depth, by_session.depth]).astype(int),\n",
    "        )\n",
    "    )\n",
    "    ax_all_sess.axhline(azel_df.Speed.median(), color=\"gray\", alpha=0.5, zorder=-10)\n",
    "    sns.violinplot(\n",
    "        azel_df,\n",
    "        x=\"Depth\",\n",
    "        y=\"Speed\",\n",
    "        hue=\"Axis\",\n",
    "        ax=ax_all_sess,\n",
    "        hue_order=[\"Nasal\", \"Temporal\"],\n",
    "        split=True,\n",
    "    )\n",
    "    label_violins(ax_all_sess, title=None, hue_order=[\"Nasal\", \"Temporal\"])\n",
    "gpby = fused_dataframe.groupby(\n",
    "    [\"recording\", \"trial_id\", \"depth\", \"temporonasal_direction\"]\n",
    ")\n",
    "df = gpby.aggregate(np.nanmean).reset_index()\n",
    "df = df[df.temporonasal_direction != 0]\n",
    "df.slow_motion *= sampling\n",
    "sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"depth\",\n",
    "    y=\"slow_motion\",\n",
    "    palette=line_colors,\n",
    "    ax=ax_all_sess,\n",
    "    split=True,\n",
    "    hue_order=[1, -1],\n",
    "    hue=\"temporonasal_direction\",\n",
    ")\n",
    "\n",
    "label_violins(ax_all_sess)\n",
    "ax_all_sess.set_xlabel(\"Depth\")\n",
    "ax_all_sess.set_ylabel(r\"Average eye velocity ($^\\circ.s^{-1}$)\")\n",
    "ax_all_sess.set_ylim([0, 30])\n",
    "ax_all_sess.axhline(np.nanmedian(df.slow_motion), color=\"gray\", alpha=0.5, zorder=-10)\n",
    "\n",
    "if False:\n",
    "    ax_all_sess = plt.subplot2grid((4, 12), (2, 7), rowspan=2, colspan=3)\n",
    "    fused_with_gray = fused_dataframe.copy()\n",
    "    fused_with_gray.loc[np.isnan(fused_with_gray.depth), \"depth\"] = 10000\n",
    "    fused_with_gray.loc[:, \"trial_id\"] = -1\n",
    "    print(fused_with_gray.depth.unique())\n",
    "    gpby = fused_with_gray.groupby(\n",
    "        [\"recording\", \"trial_id\", \"depth\", \"temporonasal_direction\"]\n",
    "    )\n",
    "    gdf = gpby.aggregate(np.nansum)\n",
    "    trial = fused_with_gray.groupby([\"recording\", \"trial_id\", \"depth\"])\n",
    "    ns = trial.aggregate(len)\n",
    "    for (r, t, d, td) in gdf.index:\n",
    "        gdf.loc[(r, t, d, td), \"saccade\"] /= ns.loc[(r, t, d), \"saccade\"]\n",
    "\n",
    "    df = gdf.reset_index()\n",
    "    sns.violinplot(\n",
    "        x=df.depth,\n",
    "        hue=df.temporonasal_direction,\n",
    "        y=df.saccade * sampling,\n",
    "        palette=list(line_colors) + [np.array([0, 0, 0, 1])],\n",
    "        split=True,\n",
    "        ax=ax_all_sess,\n",
    "        hue_order=[1, -1],\n",
    "    )\n",
    "\n",
    "    label_violins(ax_all_sess)\n",
    "    ax_all_sess.set_ylim(ax_all_sess.get_ylim()[0], 0.2)\n",
    "    ax_all_sess.set_ylabel(\"Saccade rate (Hz)\")\n",
    "    ax_all_sess.axhline(\n",
    "        np.nanmedian(df.saccade * sampling), color=\"gray\", alpha=0.5, zorder=-10\n",
    "    )\n",
    "\n",
    "\n",
    "fig.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.savefig(save_root / \"eye_tracking_panel.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_all_sess = plt.subplot(1, 1, 1)\n",
    "azel_df = pd.DataFrame(\n",
    "    dict(\n",
    "        Axis=[\"Nasal\"] * len(by_session) + [\"Temporal\"] * len(by_session),\n",
    "        Speed=np.hstack(\n",
    "            [by_session.nasal.values * sampling, by_session.temporal.values * sampling]\n",
    "        ),\n",
    "        Depth=np.hstack([by_session.depth, by_session.depth]).astype(int),\n",
    "    )\n",
    ")\n",
    "ax_all_sess.axhline(azel_df.Speed.median(), color=\"gray\", alpha=0.5, zorder=-10)\n",
    "sns.violinplot(\n",
    "    azel_df,\n",
    "    x=\"Depth\",\n",
    "    y=\"Speed\",\n",
    "    hue=\"Axis\",\n",
    "    ax=ax_all_sess,\n",
    "    hue_order=[\"Nasal\", \"Temporal\"],\n",
    "    split=True,\n",
    ")\n",
    "label_violins(ax_all_sess, title=None, hue_order=[\"Nasal\", \"Temporal\"])\n",
    "ax_all_sess.set_xlabel(\"Depth\")\n",
    "ax_all_sess.set_ylabel(r\"Average speed ($^\\circ.s^{-1}$)\")\n",
    "ax_all_sess.set_ylim([0, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_pos = [(0, 9), (0, 10), (0, 11), (1, 9), (1, 10)]\n",
    "width = 20\n",
    "bins = np.arange(-180, 180, width)\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "for imouse, mouse in enumerate([\"PZAH\", \"PZAG\"]):\n",
    "    for idepth, depth in enumerate(depth_list):\n",
    "        ax_polar = fig.add_subplot(2, 5, idepth + 1 + imouse * 5, projection=\"polar\")\n",
    "        if idepth == 0:\n",
    "            ax_polar.set_ylabel(mouse)\n",
    "        h = np.zeros(len(bins) - 1)\n",
    "        for c, dat in valid_data.items():\n",
    "            if not c.startswith(mouse):\n",
    "                continue\n",
    "            d = dat.loc[dat.depth == depth]\n",
    "            hd, _ = np.histogram(\n",
    "                d[d.amplitude_of_motion > (80 / sampling)].angle_of_motion, bins=bins\n",
    "            )\n",
    "            h += hd\n",
    "        ax_polar.bar(\n",
    "            np.deg2rad(bins[:-1]), h, width=np.deg2rad(width), color=line_colors[idepth]\n",
    "        )\n",
    "        # ax_polar.set_rlim(0, 14)\n",
    "        ax_polar.set_xticks(np.arange(0, np.pi, np.pi / 2))\n",
    "        ax_polar.set_xticklabels([\"Nasal\", \"Dorsal\"])\n",
    "        # ax_polar.set_yticks([14])\n",
    "        ax_polar.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_dataframe.recording.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpby = fused_dataframe.groupby(\n",
    "    [\"recording\", \"trial_id\", \"depth\", \"temporonasal_direction\"]\n",
    ")\n",
    "df = gpby.aggregate(np.nanmean).reset_index()\n",
    "df = df[df.temporonasal_direction != 0]\n",
    "df.slow_motion *= sampling\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"depth\",\n",
    "    y=\"slow_motion\",\n",
    "    palette=line_colors,\n",
    "    ax=ax,\n",
    "    split=True,\n",
    "    hue_order=[1, -1],\n",
    "    hue=\"temporonasal_direction\",\n",
    ")\n",
    "\n",
    "label_violins(ax)\n",
    "av = df.groupby([\"depth\", \"temporonasal_direction\"]).aggregate(np.nanmean).slow_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = av.reset_index()\n",
    "for d, ad in a.groupby(\"depth\"):\n",
    "    c = line_colors[list(depth_list).index(d)]\n",
    "    plt.plot(ad.temporonasal_direction, ad.slow_motion, marker=\"o\", color=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(line_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpby = fused_dataframe.groupby(\n",
    "    [\"recording\", \"trial_id\", \"depth\", \"temporonasal_direction\"]\n",
    ")\n",
    "gdf = gpby.aggregate(np.nansum)\n",
    "trial = fused_dataframe.groupby([\"recording\", \"trial_id\", \"depth\"])\n",
    "ns = trial.aggregate(len)\n",
    "\n",
    "for (r, t, d, td) in gdf.index:\n",
    "    gdf.loc[(r, t, d, td), \"saccade\"] /= ns.loc[(r, t, d), \"saccade\"]\n",
    "\n",
    "df = gdf.reset_index()\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.violinplot(\n",
    "    x=df.depth,\n",
    "    hue=df.temporonasal_direction,\n",
    "    y=df.saccade * sampling * 60,\n",
    "    palette=line_colors,\n",
    "    split=True,\n",
    "    ax=ax,\n",
    "    hue_order=[1, -1],\n",
    ")\n",
    "\n",
    "label_violins(ax)\n",
    "ax.set_ylabel(\"Saccade/minute\")\n",
    "# ax.set_ylim(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fused_dataframe.recording.unique()\n",
    "\n",
    "rec = recs[3]\n",
    "rec_df = fused_dataframe[fused_dataframe.recording == rec]\n",
    "rng = np.random.default_rng(seed=9876)\n",
    "for idepth, depth in enumerate(depth_list):\n",
    "    ddf = rec_df[rec_df.depth == depth]\n",
    "    trials = ddf.trial_id.unique()\n",
    "    rand = rng.integers(0, len(trials))\n",
    "    trial = trials[rand]\n",
    "    med = 0  # np.nanmedian(ddf.amplitude_of_motion)\n",
    "    for trial in trials:\n",
    "        trial_exp = ddf[ddf.trial_id == trial]\n",
    "        time = np.arange(len(trial_exp.amplitude_of_motion)) / sampling\n",
    "        plt.plot(\n",
    "            time,\n",
    "            trial_exp.amplitude_of_motion + idepth * 10 - med,\n",
    "            color=line_colors[idepth],\n",
    "        )\n",
    "plt.xlim(0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.trial_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fused_dataframe.recording.unique()\n",
    "rec = recs[3]\n",
    "rec_df = fused_dataframe[fused_dataframe.recording == rec].copy()\n",
    "\n",
    "rec_df.loc[np.isnan(rec_df.trial_id), \"trial_id\"] = -1\n",
    "n_trials = 30\n",
    "first_trial = 51\n",
    "\n",
    "\n",
    "trials_border = [\n",
    "    np.where(rec_df.trial_id == t)[0][[0, -1]]\n",
    "    for t in np.arange(n_trials) + first_trial\n",
    "]\n",
    "n_samples = 0\n",
    "b, e = trials_border[0][0], trials_border[-1][0]\n",
    "t0 = b / sampling\n",
    "non_corr = rec_df.iloc[b:e].trial_id != -1\n",
    "time = np.arange(b, e) / sampling - t0\n",
    "bg = np.array(rec_df.iloc[b:e].amplitude_of_motion.copy()) * sampling\n",
    "bg[non_corr] += np.nan\n",
    "fig = plt.figure(figsize=(7, 2))\n",
    "plt.plot(time, bg, color=\"gray\", lw=1)\n",
    "\n",
    "for i, (b, e) in enumerate(trials_border):\n",
    "    time = np.arange(b, e) / sampling - t0\n",
    "    depth = rec_df.iloc[b + 1].depth\n",
    "    color = line_colors[list(depth_list).index(depth)]\n",
    "    plt.plot(\n",
    "        time, rec_df.iloc[b:e][\"amplitude_of_motion\"] * sampling, color=color, lw=1\n",
    "    )\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylim(0, 200)\n",
    "plt.xlim(0, time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = fused_dataframe[fused_dataframe.depth == depth]\n",
    "recs = ddf.groupby([\"recording\", \"trial_id\"])\n",
    "keys = recs.groups.keys()\n",
    "rand = rng.integers(0, len(keys))\n",
    "gpd = recs[list(keys)[rand]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(\n",
    "    [\n",
    "        ns.loc[(r, t, d), \"saccade\"]\n",
    "        for (r, t, d, di) in gdf[gdf.saccade > 5 / (sampling * 60)].index\n",
    "    ]\n",
    ")\n",
    "plt.hist(ns.saccade.values / sampling, bins=np.arange(60 * 2))\n",
    "plt.hist(l / sampling, bins=np.arange(60 * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf.saccade > 5 / (sampling * 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "df.loc[idx[r, t, :, :], \"saccade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = (\n",
    "    fused_dataframe.groupby([\"recording\", \"trial_id\", \"depth\"])\n",
    "    .aggregate(len)\n",
    "    .reset_index()\n",
    ")\n",
    "ns[\"saccade\"] = ns[\"saccade\"] / sampling\n",
    "sns.violinplot(data=ns, x=\"depth\", y=\"saccade\", palette=line_colors)\n",
    "plt.gca().set_ylabel(\"Trial duration (s)\")\n",
    "plt.gca().set_ylim(0, 50)\n",
    "plt.axhline(ns[\"saccade\"].median(), color=\"gray\", alpha=0.5, zorder=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create of and rs bins\n",
    "log_range = {\n",
    "    \"rs_bin_log_min\": 0,\n",
    "    \"rs_bin_log_max\": 2.5,\n",
    "    \"rs_bin_num\": 6,\n",
    "    \"of_bin_log_min\": -1.5,\n",
    "    \"of_bin_log_max\": 3.5,\n",
    "    \"of_bin_num\": 11,\n",
    "    \"log_base\": 10,\n",
    "}\n",
    "\n",
    "rs_bins = np.logspace(\n",
    "    log_range[\"rs_bin_log_min\"],\n",
    "    log_range[\"rs_bin_log_max\"],\n",
    "    num=log_range[\"rs_bin_num\"],\n",
    "    base=log_range[\"log_base\"],\n",
    ")\n",
    "of_bins = np.logspace(\n",
    "    log_range[\"of_bin_log_min\"],\n",
    "    log_range[\"of_bin_log_max\"],\n",
    "    num=log_range[\"of_bin_num\"],\n",
    "    base=log_range[\"log_base\"],\n",
    ")\n",
    "fused_dataframe[\"rs_bin\"] = np.nan\n",
    "fused_dataframe[\"of_bin\"] = np.nan\n",
    "mask = ~np.isnan(fused_dataframe.running_speed)\n",
    "fused_dataframe.loc[mask, \"rs_bin\"] = rs_bins.searchsorted(\n",
    "    fused_dataframe.loc[mask, \"running_speed\"]\n",
    ")\n",
    "mask = ~np.isnan(fused_dataframe.optic_flow)\n",
    "fused_dataframe.loc[mask, \"of_bin\"] = of_bins.searchsorted(\n",
    "    fused_dataframe.loc[mask, \"optic_flow\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = (\n",
    "    fused_dataframe.groupby([\"recording\", \"trial_id\", \"depth\"])\n",
    "    .aggregate(np.nanmean)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(4, 1, 1)\n",
    "sns.violinplot(data=ddf, x=\"depth\", y=\"running_speed\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 2)\n",
    "sns.violinplot(data=ddf, x=\"depth\", y=\"rs_bin\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 3)\n",
    "sns.boxenplot(data=ddf, x=\"depth\", y=\"saccade\", palette=line_colors, ax=ax)\n",
    "ax.set_ylim(0, 0.05)\n",
    "ax = plt.subplot(4, 1, 4)\n",
    "sns.violinplot(data=ddf, x=\"depth\", y=\"amplitude_of_motion\", palette=line_colors, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_dataframe[\"depth\"] = fused_dataframe[\"depth\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = (\n",
    "    fused_dataframe.groupby([\"recording\", \"trial_id\", \"of_bin\"])\n",
    "    .aggregate(np.nanmean)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(4, 1, 1)\n",
    "sns.violinplot(data=ddf, x=\"of_bin\", y=\"running_speed\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 2)\n",
    "sns.violinplot(data=ddf, x=\"of_bin\", y=\"depth\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 3)\n",
    "sns.violinplot(data=ddf, x=\"of_bin\", y=\"optic_flow\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 4)\n",
    "sns.violinplot(\n",
    "    data=ddf, x=\"of_bin\", y=\"amplitude_of_motion\", palette=line_colors, ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = (\n",
    "    fused_dataframe.groupby([\"recording\", \"trial_id\", \"rs_bin\"])\n",
    "    .aggregate(np.nanmax)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(4, 1, 1)\n",
    "sns.violinplot(data=ddf, x=\"rs_bin\", y=\"running_speed\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 2)\n",
    "sns.violinplot(data=ddf, x=\"rs_bin\", y=\"depth\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 3)\n",
    "sns.violinplot(data=ddf, x=\"rs_bin\", y=\"optic_flow\", palette=line_colors, ax=ax)\n",
    "ax = plt.subplot(4, 1, 4)\n",
    "sns.boxenplot(data=ddf, x=\"rs_bin\", y=\"amplitude_of_motion\", palette=line_colors, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cottage_eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f379f14f554b5908c89078a779246902196c66e33ef5358781a357c6bf6c72d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
