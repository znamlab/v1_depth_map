{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi depth experiments\n",
    "\n",
    "Corridors with spheres at multidepths presented simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"colasa_3d-vision_revisions\"\n",
    "session_name = \"PZAG16.3b_S20250317\"\n",
    "session_name = \"PZAH17.1e_S20250403\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yiran workflow is to call sbatch_session on all sessions, like that:\n",
    "\n",
    "if False:\n",
    "    from cottage_analysis.pipelines import pipeline_utils\n",
    "\n",
    "    pipeline_filename = \"run_analysis_pipeline.sh\"\n",
    "    conflicts = \"overwrite\"\n",
    "    photodiode_protocol = 5\n",
    "    pipeline_utils.sbatch_session(\n",
    "        project=project,\n",
    "        session_name=session_name,\n",
    "        pipeline_filename=pipeline_filename,\n",
    "        conflicts=conflicts,\n",
    "        photodiode_protocol=photodiode_protocol,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Analyse the multidepth experiments\n",
    "\n",
    "In theory the same pipeline should work, if we change the protocol base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.pipelines import analysis_pipeline\n",
    "import flexiznam as flz\n",
    "\n",
    "# We can just run the same pipeline. It will skip depth and rsof fit and just run the\n",
    "# the rf fit\n",
    "protocol_base = \"SpheresPermTubeReward\"\n",
    "if False:\n",
    "    analysis_pipeline.main(\n",
    "        project,\n",
    "        session_name,\n",
    "        conflicts=\"overwrite\",\n",
    "        photodiode_protocol=5,\n",
    "        use_slurm=False,\n",
    "        run_depth_fit=False,\n",
    "        run_rf=True,\n",
    "        run_rsof_fit=False,\n",
    "        run_plot=True,\n",
    "        protocol_base=\"SpheresPermTubeReward_multidepth\",\n",
    "    )\n",
    "else:\n",
    "    # here we do it step by step for debugging\n",
    "    from cottage_analysis.analysis import spheres\n",
    "\n",
    "    flexilims_session = flz.get_flexilims_session(project)\n",
    "    print(\"---Start synchronisation...---\")\n",
    "    vs_df_all, trials_df_all = spheres.sync_all_recordings(\n",
    "        session_name=session_name,\n",
    "        flexilims_session=flexilims_session,\n",
    "        project=project,\n",
    "        filter_datasets={\"anatomical_only\": 3},\n",
    "        recording_type=\"two_photon\",\n",
    "        protocol_base=protocol_base,\n",
    "        photodiode_protocol=5,\n",
    "        return_volumes=True,\n",
    "        conflicts=\"skip\",\n",
    "    )\n",
    "\n",
    "    # Add trial number to flexilims\n",
    "    trial_no_closedloop = len(trials_df_all[trials_df_all[\"closed_loop\"] == 1])\n",
    "    trial_no_openloop = len(trials_df_all[trials_df_all[\"closed_loop\"] == 0])\n",
    "    ndepths = len(trials_df_all[\"depth\"].unique())\n",
    "    flz.update_entity(\n",
    "        \"session\",\n",
    "        name=session_name,\n",
    "        mode=\"update\",\n",
    "        attributes={\n",
    "            \"closedloop_trials\": trial_no_closedloop,\n",
    "            \"openloop_trials\": trial_no_openloop,\n",
    "            \"ndepths\": ndepths,\n",
    "        },\n",
    "        flexilims_session=flexilims_session,\n",
    "    )\n",
    "\n",
    "    suite2p_datasets = flz.get_datasets(\n",
    "        origin_name=session_name,\n",
    "        dataset_type=\"suite2p_rois\",\n",
    "        project_id=project,\n",
    "        flexilims_session=flexilims_session,\n",
    "        return_dataseries=False,\n",
    "        filter_datasets={\"anatomical_only\": 3},\n",
    "    )\n",
    "    suite2p_dataset = suite2p_datasets[0]\n",
    "    frame_rate = suite2p_dataset.extra_attributes[\"fs\"]\n",
    "\n",
    "    is_multidepth = \"multidepth\" in protocol_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flexiznam as flz\n",
    "from cottage_analysis.pipelines import analysis_pipeline\n",
    "import flexiznam as flz\n",
    "\n",
    "exclude_datasets = None\n",
    "\n",
    "harp_is_in_recording = True\n",
    "use_onix = False\n",
    "conflicts = \"skip\"\n",
    "sync_kwargs = None\n",
    "ephys_kwargs = None\n",
    "# We can just run the same pipeline. It will skip depth and rsof fit and just run the\n",
    "# the rf fit\n",
    "protocol_base = \"SpheresPermTubeReward_multidepth\"\n",
    "flexilims_session = flz.get_flexilims_session(project_id=project)\n",
    "assert flexilims_session is not None or project is not None\n",
    "filter_datasets = {\"anatomical_only\": 3}\n",
    "recording_type = \"two_photon\"\n",
    "protocol_base = protocol_base\n",
    "photodiode_protocol = 5\n",
    "return_volumes = True\n",
    "\n",
    "if flexilims_session is None:\n",
    "    flexilims_session = flz.get_flexilims_session(project_id=project)\n",
    "\n",
    "exp_session = flz.get_entity(\n",
    "    datatype=\"session\", name=session_name, flexilims_session=flexilims_session\n",
    ")\n",
    "recordings = flz.get_entities(\n",
    "    datatype=\"recording\",\n",
    "    origin_id=exp_session[\"id\"],\n",
    "    query_key=\"recording_type\",\n",
    "    query_value=recording_type,\n",
    "    flexilims_session=flexilims_session,\n",
    ")\n",
    "recordings = recordings[recordings.name.str.contains(protocol_base)]\n",
    "if \"exclude_reason\" in recordings.columns:\n",
    "    recordings = recordings[recordings[\"exclude_reason\"].isna()]\n",
    "from cottage_analysis.analysis.spheres import *\n",
    "\n",
    "load_onix = False if recording_type == \"two_photon\" else True\n",
    "for i, recording_name in enumerate(recordings.name):\n",
    "    print(f\"Processing recording {i+1}/{len(recordings)}\")\n",
    "    recording, harp_recording, onix_rec = get_relevant_recordings(\n",
    "        recording_name, flexilims_session, harp_is_in_recording, load_onix\n",
    "    )\n",
    "    break\n",
    "vs_df = synchronisation.generate_vs_df(\n",
    "    recording=recording,\n",
    "    photodiode_protocol=photodiode_protocol,\n",
    "    flexilims_session=flexilims_session,\n",
    "    harp_recording=harp_recording,\n",
    "    onix_recording=onix_rec if use_onix else None,\n",
    "    project=project,\n",
    "    conflicts=conflicts,\n",
    "    sync_kwargs=sync_kwargs,\n",
    "    protocol_base=protocol_base,\n",
    ")\n",
    "imaging_df = synchronisation.generate_imaging_df(\n",
    "    vs_df=vs_df,\n",
    "    recording=recording,\n",
    "    flexilims_session=flexilims_session,\n",
    "    filter_datasets=filter_datasets,\n",
    "    exclude_datasets=exclude_datasets,\n",
    "    return_volumes=return_volumes,\n",
    ")\n",
    "imaging_df = format_imaging_df(imaging_df=imaging_df, recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.io_module.visstim import get_frame_log, get_param_log\n",
    "\n",
    "harp_ds = flz.get_datasets(\n",
    "    flexilims_session=flexilims_session,\n",
    "    origin_name=recording.name,\n",
    "    dataset_type=\"harp\",\n",
    "    allow_multiple=False,\n",
    "    return_dataseries=False,\n",
    ")\n",
    "frame_log = get_frame_log(\n",
    "    harp_ds.flexilims_session,\n",
    "    harp_recording=harp_recording,\n",
    "    vis_stim_recording=recording,\n",
    ")\n",
    "param_log = get_param_log(\n",
    "    harp_ds.flexilims_session,\n",
    "    harp_recording=harp_recording,\n",
    "    vis_stim_recording=recording,\n",
    "    multidepth=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = imaging_df.index[imaging_df.stim.diff() == 1]\n",
    "offsets = imaging_df.index[imaging_df.stim.diff() == -1]\n",
    "\n",
    "# we want to clean fast alternation, keep only onsets where the previous 2s were not\n",
    "# stim\n",
    "onset_times = imaging_df[\"imaging_harptime\"].loc[onsets]\n",
    "start_windows = imaging_df[\"imaging_harptime\"].searchsorted(onset_times - 2)\n",
    "is_valid_onset = np.zeros(len(onsets), dtype=bool)\n",
    "for i, start in enumerate(start_windows):\n",
    "    chunk = imaging_df[\"stim\"].iloc[start : onsets[i]]\n",
    "    is_valid_onset[i] = chunk.sum() == 0\n",
    "clean_onsets = onsets[is_valid_onset]\n",
    "\n",
    "# Similarly for offsets, we want to keep only offsets where the next 2s were not stim\n",
    "offset_times = imaging_df[\"imaging_harptime\"].loc[offsets]\n",
    "end_windows = imaging_df[\"imaging_harptime\"].searchsorted(offset_times + 2)\n",
    "end_windows = np.clip(end_windows, 0, len(imaging_df) - 1)\n",
    "is_valid_offset = np.zeros(len(offsets), dtype=bool)\n",
    "for i, end in enumerate(end_windows):\n",
    "    chunk = imaging_df[\"stim\"].iloc[offsets[i] : end]\n",
    "    is_valid_offset[i] = chunk.sum() == 0\n",
    "clean_offsets = offsets[is_valid_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reward logs\n",
    "rewards = {}\n",
    "for fid, fname in harp_ds.extra_attributes[\"csv_files\"].items():\n",
    "    if fid.startswith(\"Reward\"):\n",
    "        depth = int(fid.split(\"_\")[1].strip(\"cm.csv\"))\n",
    "        rewards[depth] = pd.read_csv(harp_ds.path_full / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t0 = imaging_df[\"imaging_harptime\"].min()\n",
    "plt.figure(figsize=(25, 6))\n",
    "ax1 = plt.subplot(311)\n",
    "depths = list((imaging_df[\"depth\"].unique() * 100).astype(int))\n",
    "for i, (log, df) in enumerate(param_log.groupby(\"logger_fname\")):\n",
    "    depth = int(log.split(\"_\")[1].strip(\"cm.csv\"))\n",
    "    print(f\"{log}: {len(df)}\")\n",
    "    stim = (df.Radius > 0).astype(float) * 0.5\n",
    "    # stim[stim == 0] = np.nan\n",
    "    x = (df.HarpTime - t0).values\n",
    "    # x = df.Frameindex.values\n",
    "    plt.plot(x, stim + depths.index(depth), \"|\", label=depth)\n",
    "    rw = rewards[depth]\n",
    "    plt.plot(\n",
    "        rw[\"HarpTime\"] - t0,\n",
    "        rw[\"Reward\"] * 0.5 + depths.index(depth),\n",
    "        \"|\",\n",
    "        color=\"k\",\n",
    "        alpha=1,\n",
    "        ms=20,\n",
    "    )\n",
    "plt.legend()\n",
    "plt.ylabel(\"Visual stim per depth - param_log\")\n",
    "\n",
    "plt.subplot(312, sharex=ax1)\n",
    "plt.plot(vs_df.monitor_harptime - t0, vs_df.Radius > 0, \"|\")\n",
    "plt.ylabel(\"vs_df\")\n",
    "plt.subplot(313, sharex=ax1)\n",
    "# now using imaging_df\n",
    "plt.plot(imaging_df[\"imaging_harptime\"] - t0, imaging_df[\"depth\"] > 0, \"|\")\n",
    "plt.plot(imaging_df[\"imaging_harptime\"] - t0, imaging_df[\"stim\"] * 0.5)\n",
    "plt.plot(\n",
    "    imaging_df.loc[onsets, \"imaging_harptime\"] - t0,\n",
    "    imaging_df.loc[onsets, \"stim\"] * 0.5,\n",
    "    \"o\",\n",
    "    color=\"g\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    imaging_df.loc[offsets, \"imaging_harptime\"] - t0,\n",
    "    imaging_df.loc[offsets, \"stim\"] * 0.5,\n",
    "    \"o\",\n",
    "    color=\"r\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    imaging_df.loc[clean_onsets, \"imaging_harptime\"] - t0,\n",
    "    imaging_df.loc[clean_onsets, \"stim\"] * 0.5 + 0.2,\n",
    "    \"*\",\n",
    "    color=\"g\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    imaging_df.loc[clean_offsets, \"imaging_harptime\"] - t0,\n",
    "    imaging_df.loc[clean_offsets, \"stim\"] * 0.5 + 0.2,\n",
    "    \"*\",\n",
    "    color=\"r\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.ylabel(\"imaging_df\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "ax1.set_xlim(1000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = param_log\n",
    "stim = (df.Radius > 0).astype(float) * 0.5\n",
    "# stim[stim == 0] = np.nan\n",
    "x = (df.HarpTime - t0).values\n",
    "x = df.index.values\n",
    "plt.plot(x, stim + i, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(onsets, imaging_df.stim[onsets], c=\"red\")\n",
    "plt.scatter(offsets, imaging_df.stim[offsets], c=\"blue\")\n",
    "plt.plot(imaging_df.index, imaging_df.stim)\n",
    "plt.xlim(500, 550)\n",
    "\n",
    "\n",
    "was_blank = imaging_df.stim.rolling(window=10).sum() == 0\n",
    "plt.plot(imaging_df.index, was_blank.shift(-10) * 0.5)\n",
    "\n",
    "# plt.plot(imaging_df.index, was_blank.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(offsets).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imaging_df[\"stim\"] = np.nan\n",
    "imaging_df.loc[imaging_df.depth.notnull(), \"stim\"] = 1\n",
    "imaging_df.loc[imaging_df.depth < 0, \"stim\"] = 0\n",
    "onsets = imaging_df.stim.diff() == 1\n",
    "offsets = imaging_df.stim.diff() == -1\n",
    "\n",
    "# Stim is somewhat bistable at onsext and offset. Only keep onset that have at least 10\n",
    "# frames of non-stim before\n",
    "onsets = imaging_df.stim.diff() == 1\n",
    "offsets = imaging_df.stim.diff() == -1\n",
    "# Keep only onset where the previous 10 frames were blank and the offsets where\n",
    "# the next 10 frames are blank\n",
    "was_blank = imaging_df.stim.rolling(window=10).sum() == 0\n",
    "onsets = onsets & was_blank.shift(1)\n",
    "onsets = imaging_df.index[onsets]\n",
    "offsets = offsets & was_blank.shift(-10)\n",
    "offsets = imaging_df.index[offsets]\n",
    "if offsets[0] < onsets[0]:\n",
    "    print(\"Warning: offsets start before onsets! Double check!\")\n",
    "    offsets = offsets[1:]\n",
    "    assert (\n",
    "        offsets[0] > onsets[0]\n",
    "    ), \"Warning: 2 offsets start before onsets! Double check!\"\n",
    "is_stim = pd.Series(index=imaging_df.index, data=False, dtype=bool)\n",
    "for on, off in zip(onsets, offsets):\n",
    "    is_stim[on:off] = True\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(imaging_df[\"stim\"], label=\"stim\")\n",
    "plt.scatter(imaging_df.index[onsets], imaging_df[\"stim\"][onsets], marker=\"o\", color=\"g\")\n",
    "plt.scatter(\n",
    "    imaging_df.index[offsets], imaging_df[\"stim\"][offsets], marker=\"o\", color=\"r\"\n",
    ")\n",
    "plt.plot(is_stim, label=\"is_stim\", color=\"purple\")\n",
    "\n",
    "plt.xlim([3591 - 1000, 3591 + 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 280\n",
    "t0 = imaging_df.iloc[b][\"imaging_harptime\"]\n",
    "subset_df = imaging_df.iloc[b : b + 10]\n",
    "print(\n",
    "    subset_df[\n",
    "        [\n",
    "            \"imaging_harptime\",\n",
    "            \"monitor_harptime\",\n",
    "            \"stimulus_harptime\",\n",
    "            \"mouse_z_harptime\",\n",
    "        ]\n",
    "    ]\n",
    "    - t0\n",
    ")\n",
    "subset_df.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "imaging_df[\"stim\"] = np.nan\n",
    "imaging_df.loc[imaging_df.depth.notnull(), \"stim\"] = 1\n",
    "imaging_df.loc[imaging_df.depth < 0, \"stim\"] = 0\n",
    "imaging_df_simple = imaging_df[\n",
    "    (imaging_df[\"stim\"].diff() != 0) & (imaging_df[\"stim\"]).notnull()\n",
    "].copy()\n",
    "imaging_df_simple.depth = np.round(imaging_df_simple.depth, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(imaging_df.stim)\n",
    "plt.xlim(200, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_df[\"temp_time\"] = (\n",
    "    imaging_df[\"imaging_harptime\"] - imaging_df[\"imaging_harptime\"].iloc[284]\n",
    ")\n",
    "imaging_df.iloc[275:300][[\"eye_z\", \"stim\", \"trial_idx\", \"depth\", \"temp_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_closedloop = True\n",
    "sfx = \"_closedloop\"\n",
    "frames_all, imaging_df_all = spheres.regenerate_frames_all_recordings(\n",
    "    session_name=session_name,\n",
    "    flexilims_session=flexilims_session,\n",
    "    project=None,\n",
    "    filter_datasets={\"anatomical_only\": 3},\n",
    "    recording_type=\"two_photon\",\n",
    "    is_closedloop=is_closedloop,\n",
    "    is_multidepth=is_multidepth,\n",
    "    protocol_base=protocol_base,\n",
    "    photodiode_protocol=5,\n",
    "    return_volumes=True,\n",
    "    verbose=False,\n",
    "    resolution=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fitting RF{sfx}...\")\n",
    "# The first step is to estimate hyperparameters\n",
    "if False:\n",
    "    (\n",
    "        coef,\n",
    "        r2,\n",
    "        best_reg_xys,\n",
    "        best_reg_depths,\n",
    "    ) = spheres.fit_3d_rfs_hyperparam_tuning(\n",
    "        imaging_df_all,\n",
    "        frames_all[:, :, int(frames_all.shape[2] // 2) :],\n",
    "        reg_xys=np.geomspace(2.5, 10240, 13),\n",
    "        reg_depths=np.geomspace(2.5, 10240, 13),\n",
    "        shift_stim=2,\n",
    "        use_col=\"dffs\",\n",
    "        k_folds=5,\n",
    "        tune_separately=True,\n",
    "        validation=False,\n",
    "    )\n",
    "else:\n",
    "    imaging_df = imaging_df_all\n",
    "    frames = frames_all[..., int(frames_all.shape[2] // 2) :]\n",
    "    reg_xys = [20, 40, 80, 160, 320]\n",
    "    reg_depths = [20, 40, 80, 160, 320]\n",
    "    shift_stim = 2\n",
    "    use_col = \"dffs\"\n",
    "    k_folds = 5\n",
    "    tune_separately = True\n",
    "    validation = True\n",
    "    r2_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cottage_analysis.analysis.spheres import fit_3d_rfs, fit_3d_rfs_multidepth\n",
    "\n",
    "depth_list = imaging_df.depth.dropna().unique()\n",
    "depth_list = np.sort(depth_list[depth_list > 0])\n",
    "all_coef = np.zeros(\n",
    "    (\n",
    "        len(reg_xys) * len(reg_depths),\n",
    "        k_folds,\n",
    "        frames.shape[-2] * frames.shape[-1] * len(depth_list) + 1,\n",
    "        imaging_df.loc[0, \"dffs\"].shape[1],\n",
    "    )\n",
    ")\n",
    "all_r2s = np.zeros(\n",
    "    (len(reg_xys) * len(reg_depths), imaging_df.loc[0, \"dffs\"].shape[1], 2)\n",
    ")\n",
    "hyperparams = np.zeros((len(reg_xys) * len(reg_depths), 2))\n",
    "good_neuron_percs = np.zeros((len(reg_xys), len(reg_depths)))\n",
    "nrois = imaging_df.loc[0, \"dffs\"].shape[1]\n",
    "if frames.ndim == 4:\n",
    "    fit_func = fit_3d_rfs_multidepth\n",
    "elif frames.ndim == 3:\n",
    "    fit_func = fit_3d_rfs\n",
    "else:\n",
    "    raise ValueError(\"frames must be 3D or 4D\")\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r2s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "reg_xy = reg_xys[i]\n",
    "reg_depth = reg_depths[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_xy = reg_xy\n",
    "reg_depth = reg_depth\n",
    "shift_stim = shift_stim\n",
    "use_col = use_col\n",
    "k_folds = k_folds\n",
    "choose_rois = ()\n",
    "validation = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "ndepths, nframes, nelev, nazim = frames.shape\n",
    "resps = zscore(np.concatenate(imaging_df[use_col]), axis=0)\n",
    "if len(choose_rois) > 0:\n",
    "    resps = resps[:, choose_rois]\n",
    "depths = imaging_df.depth.unique()\n",
    "depths = depths[~np.isnan(depths)]\n",
    "depths = depths[depths > 0]\n",
    "depths = np.sort(depths)\n",
    "\n",
    "is_stim = imaging_df.depth > 0\n",
    "trial_start_stop = np.diff(is_stim.astype(int))\n",
    "trial_idx = np.cumsum(np.hstack([0, trial_start_stop == 1])).astype(float)\n",
    "trial_idx[imaging_df.depth.isna()] = np.nan\n",
    "trial_idx[imaging_df.depth < 0] = np.nan\n",
    "imaging_df[\"trial_idx\"] = trial_idx\n",
    "\n",
    "assert depths.shape[0] == frames.shape[0]\n",
    "# Shift to account for response lag\n",
    "X = np.roll(frames, shift_stim, axis=1)\n",
    "X = np.swapaxes(X, 0, 1)  # put back frame number as first axis\n",
    "# (now we have frame, depth, ele, azi)\n",
    "X = X.reshape(nframes, -1)  # flatten\n",
    "\n",
    "L = spheres.laplace_matrix(nelev, nazim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_df.trial_idx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L.shape)\n",
    "print(X.shape)\n",
    "nazim * nelev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls = []\n",
    "Ls_depth = []\n",
    "\n",
    "for idepth, depth in enumerate(depths):\n",
    "    L_xy = np.zeros((L.shape[0], X.shape[1]))\n",
    "    L_xy[:, idepth * L.shape[1] : (idepth + 1) * L.shape[1]] = L\n",
    "    Ls.append(L_xy)\n",
    "    # add regularization penalty on the second derivative of the coefficients\n",
    "    # along the depth axis\n",
    "    L_depth = np.zeros((L.shape[1], X.shape[1]))\n",
    "    L_depth[:, idepth * L.shape[1] : (idepth + 1) * L.shape[1]] = (\n",
    "        np.identity(L.shape[1]) * 2\n",
    "    )\n",
    "    if idepth > 0:\n",
    "        L_depth[:, (idepth - 1) * L.shape[1] : idepth * L.shape[1]] = -np.identity(\n",
    "            L.shape[1]\n",
    "        )\n",
    "    if idepth < depths.shape[0] - 1:\n",
    "        L_depth[:, (idepth + 1) * L.shape[1] : (idepth + 2) * L.shape[1]] = (\n",
    "            -np.identity(L.shape[1])\n",
    "        )\n",
    "    Ls_depth.append(L_depth)\n",
    "L = np.concatenate(Ls, axis=0)\n",
    "L = np.concatenate([L, np.zeros((L.shape[0], 1))], axis=1)\n",
    "L_depth = np.concatenate(Ls_depth, axis=0)\n",
    "L_depth = np.concatenate([L_depth, np.zeros((L_depth.shape[0], 1))], axis=1)\n",
    "# add bias\n",
    "X = np.concatenate([X, np.ones((X.shape[0], 1))], axis=1)\n",
    "coefs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L_depth.shape)\n",
    "print(L.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 0 for train and -1 for test, 1 for validation prediction\n",
    "n_splits = 3 if validation else 2\n",
    "Y_pred = np.zeros((resps.shape[0], resps.shape[1], n_splits)) * np.nan\n",
    "# randomly split trials into training and test sets\n",
    "kfold = KFold(n_splits=k_folds, random_state=42, shuffle=True)\n",
    "# Use validation set to select the best regularization parameters (train, val, test),\n",
    "# or use test set to evaluate performance (train, test)\n",
    "trials = imaging_df.trial_idx.dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_trials, test_trials in kfold.split(trials):\n",
    "    if validation:\n",
    "        train_trials, validation_trials = spheres.train_test_split(\n",
    "            train_trials,\n",
    "            test_size=(1 / (k_folds - 1)),\n",
    "        )\n",
    "        validation_idx = np.isin(imaging_df.trial_idx, validation_trials)\n",
    "    train_idx = np.isin(imaging_df.trial_idx, train_trials)\n",
    "    test_idx = np.isin(imaging_df.trial_idx, test_trials)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X[train_idx, :], reg_xy * L, reg_depth * L_depth], axis=0)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.linalg.inv(X_train.T @ X_train) @ X_train.T\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.concatenate(\n",
    "    [\n",
    "        resps[train_idx, :],\n",
    "        np.zeros((L.shape[0], resps.shape[1])),\n",
    "        np.zeros((L_depth.shape[0], resps.shape[1])),\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "coef = Q @ Y_train\n",
    "coefs.append(coef)\n",
    "\n",
    "if validation:\n",
    "    idxs = [train_idx, validation_idx, test_idx]\n",
    "else:\n",
    "    idxs = [train_idx, test_idx]\n",
    "for isplit, idx in enumerate(idxs):\n",
    "    Y_pred[idx, :, isplit] = X[idx, :] @ coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.zeros((resps.shape[1], n_splits)) * np.nan\n",
    "for isplit in range(n_splits):\n",
    "    use_idx = np.isfinite(Y_pred[:, 0, isplit])\n",
    "    residual_var = np.sum(\n",
    "        (Y_pred[use_idx, :, isplit] - resps[use_idx, :]) ** 2,\n",
    "        axis=0,\n",
    "    )\n",
    "    total_var = np.sum(\n",
    "        (resps[use_idx, :] - np.mean(resps[use_idx, :], axis=0)) ** 2, axis=0\n",
    "    )\n",
    "    r2[:, isplit] = 1 - residual_var / total_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(imaging_df.depth)\n",
    "plt.xlim(100, 1000)\n",
    "plt.ylim(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(imaging_df.depth > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.analysis.spheres import fit_3d_rfs_hyperparam_tuning\n",
    "\n",
    "(\n",
    "    coef,\n",
    "    r2,\n",
    "    best_reg_xys,\n",
    "    best_reg_depths,\n",
    ") = spheres.fit_3d_rfs_hyperparam_tuning(\n",
    "    imaging_df_all,\n",
    "    frames_all[..., int(frames_all.shape[-1] // 2) :],\n",
    "    reg_xys=np.geomspace(2.5, 10240, 13),\n",
    "    reg_depths=np.geomspace(2.5, 10240, 13),\n",
    "    shift_stim=2,\n",
    "    use_col=\"dffs\",\n",
    "    k_folds=5,\n",
    "    tune_separately=True,\n",
    "    validation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.analysis.spheres import fit_3d_rfs_ipsi\n",
    "\n",
    "print(\"Fitting ipsi RF...\")\n",
    "coef_ipsi, r2_ipsi = spheres.fit_3d_rfs_ipsi(\n",
    "    imaging_df_all,\n",
    "    frames_all[:, :, : int(frames_all.shape[2] // 2)],\n",
    "    best_reg_xys,\n",
    "    best_reg_depths,\n",
    "    shift_stim=2,\n",
    "    use_col=\"dffs\",\n",
    "    k_folds=5,\n",
    "    validation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the depth and frame axes of the frames array and make in 2D, with shape\n",
    "# (n_frames, n_depths * nelev * nazi)\n",
    "frames = np.swapaxes(frames, 0, 1)\n",
    "frames = frames.reshape(frames.shape[0], -1)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert depths.shape[0] == frames.shape[0]\n",
    "X = np.zeros((frames.shape[1], frames.shape[2] * frames.shape[3] * depths.shape[0]))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx = np.zeros_like(imaging_df.depth)\n",
    "trial_idx = np.cumsum(\n",
    "    np.logical_and(np.abs(imaging_df.depth.diff()) > 0, imaging_df.depth > 0)\n",
    ")\n",
    "trial_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spheres = {}\n",
    "frame_reconstruction = {}\n",
    "for csv_id, csv_file in harp_dataset.extra_attributes[\"csv_files\"].items():\n",
    "    if not csv_id.startswith(\"NewParams\"):\n",
    "        # not a parameter file\n",
    "        continue\n",
    "    depth = int(csv_id.split(\"_\")[-1][:-2])\n",
    "    param_log = pd.read_csv(harp_dataset.path_full / csv_file)\n",
    "    frames, n_spheres_per_frame = regenerate_frames(\n",
    "        frame_times=imaging_df.imaging_harptime,\n",
    "        trials_df=trials_df,\n",
    "        vs_df=vs_df,\n",
    "        param_logger=param_log,\n",
    "        time_column=\"HarpTime\",\n",
    "        resolution=resolution,\n",
    "        sphere_size=sphere_size,\n",
    "        azimuth_limits=(20, 120),\n",
    "        elevation_limits=(-40, 40),\n",
    "        verbose=False,\n",
    "        output_datatype=\"int8\",\n",
    "        output=None,\n",
    "        return_sphere_number=True,\n",
    "        # flip_x=True,\n",
    "    )\n",
    "    has_px = frames.sum(axis=(1, 2)) > 0\n",
    "    frame_reconstruction[depth] = frames\n",
    "    n_spheres[depth] = n_spheres_per_frame\n",
    "    print(f\"Depth {depth}: {len(frames)} frames, {n_spheres_per_frame.sum()} spheres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_csvs = harp_dataset.extra_attributes[\"csv_files\"]\n",
    "rewards_logs = {}\n",
    "newparams_logs = {}\n",
    "trial_ends = {}\n",
    "for csvname, filename in harp_csvs.items():\n",
    "    if \"RewardLog\" in csvname:\n",
    "        rewards_logs[csvname] = pd.read_csv(harp_dataset.path_full / filename)\n",
    "    elif \"NewParams\" in csvname:\n",
    "        newparams_logs[csvname] = pd.read_csv(harp_dataset.path_full / filename)\n",
    "        depth = int(csvname.split(\"_\")[-1][:-2])\n",
    "        radius = newparams_logs[csvname][\"Radius\"].values.astype(float)\n",
    "        r = (radius == -9999).astype(int)\n",
    "        corridor_end = np.diff(r) == 1\n",
    "        trial_ends[depth] = newparams_logs[csvname].iloc[:-1][corridor_end].HarpTime\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Found {len(rewards_logs)} RewardLog files and {len(newparams_logs)} NewParams files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "depths = sorted(frame_reconstruction.keys())\n",
    "n_per_frame = np.vstack([n_spheres[depth] for depth in depths])\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "for idepth, depth in enumerate(depths):\n",
    "    ax.scatter(\n",
    "        np.arange(n_per_frame.shape[1]), n_per_frame[idepth], label=f\"Depth {depth}\"\n",
    "    )\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"Number of Spheres per Frame at Different Depths\")\n",
    "ax.set_xlabel(\"Frame Index\")\n",
    "ax.set_ylabel(\"Number of Spheres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_reconstruction[depths[0]].shape)\n",
    "all_frames = np.concatenate(\n",
    "    [frame_reconstruction[depth][None, ...] for depth in depths], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = imaging_df.imaging_harptime.min()\n",
    "frame_times = imaging_df.imaging_harptime\n",
    "m = n_per_frame.sum(axis=0)\n",
    "tend = trial_ends[depths[0]].values - t0\n",
    "plt.scatter(tend, np.zeros_like(tend) + 4, color=\"darkred\", label=\"Trial end\")\n",
    "plt.plot(frame_times - t0, m)\n",
    "plt.ylim(0, 8)\n",
    "plt.xlim(2500, 2700)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Number of spheres\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_reconstruction[10][5].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_reconstruction[10][500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndepths = len(depths)\n",
    "fig, axes = plt.subplots(ndepths, 1, figsize=(4, 10))\n",
    "frame_id = 5\n",
    "for idepth, depth in enumerate(depths):\n",
    "    ax = axes[idepth]\n",
    "    ax.imshow(all_frames[idepth, frame_id], vmin=0, vmax=1, interpolation=\"none\")\n",
    "    ax.set_ylabel(f\"{depth}cm\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = flz.get_entity(name=session_name, datatype=\"session\", flexilims_session=flm_sess)\n",
    "recording = flz.get_entity(\n",
    "    origin_id=sess.id,\n",
    "    datatype=\"recording\",\n",
    "    query_key=\"protocol\",\n",
    "    query_value=\"SpheresPermTubeReward_multidepth\",\n",
    "    flexilims_session=flm_sess,\n",
    ")\n",
    "print(\"Recording:\", recording.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_dataset = flz.get_datasets(\n",
    "    origin_id=recording.id,\n",
    "    dataset_type=\"harp\",\n",
    "    flexilims_session=flm_sess,\n",
    "    allow_multiple=False,\n",
    ")\n",
    "print(\"HARP dataset:\", harp_dataset.full_name)\n",
    "for k, v in harp_dataset.extra_attributes.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.preprocessing import synchronisation\n",
    "\n",
    "photodiode_protocol = 5\n",
    "\n",
    "vs_df = synchronisation.generate_vs_df(\n",
    "    recording=recording,\n",
    "    photodiode_protocol=photodiode_protocol,\n",
    "    flexilims_session=flm_sess,\n",
    "    harp_recording=recording,\n",
    "    onix_recording=None,\n",
    "    project=project,\n",
    "    protocol_base=\"SpheresPermTubeReward_multidepth\",\n",
    "    sync_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regenerating frames\n",
    "\n",
    "We want to regenerate the stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10\n",
    "sphere_size = 10\n",
    "azimuth_limits = (-120, 120)\n",
    "elevation_limits = (-40, 40)\n",
    "\n",
    "from cottage_analysis.io_module.visstim import get_param_log\n",
    "\n",
    "param_log = get_param_log(\n",
    "    flexilims_session=flm_sess,\n",
    "    harp_recording=recording,\n",
    "    vis_stim_recording=recording,\n",
    "    multidepth=True,\n",
    ")\n",
    "param_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_log.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the frame we want to reconstruct, i.e. those with something on the screen\n",
    "\n",
    "frame_times = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valid_depth = sorted(param_log.query(\"Radius > 0\").Radius.unique())\n",
    "azi_pixels = np.arange(azimuth_limits[0], azimuth_limits[1] + 1, resolution)\n",
    "ele_pixels = np.arange(elevation_limits[0], elevation_limits[1] + 1, resolution)\n",
    "frame_shape = (len(valid_depth), len(azi_pixels), len(ele_pixels))\n",
    "frame_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(2, 1, 1)\n",
    "plt.plot(param_log[\"Frameindex\"].values[300:500], \"o\")\n",
    "plt.subplot(2, 1, 2, sharex=ax)\n",
    "bad = np.diff(param_log[\"Frameindex\"].values[300:500]) < 0\n",
    "plt.plot(np.diff(param_log[\"Frameindex\"].values[300:500])[bad], \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexilims_session = flm_sess\n",
    "photodiode_protocol = 5\n",
    "protocol_base = \"SpheresPermTubeReward_multidepth\"\n",
    "harp_recording = recording\n",
    "onix_recording = None\n",
    "conflicts = \"skip\"\n",
    "sync_kwargs = None\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from cottage_analysis.utilities.misc import get_str_or_recording\n",
    "\n",
    "from cottage_analysis.io_module.harp import load_harpmessage\n",
    "from cottage_analysis.io_module.visstim import get_frame_log, get_param_log\n",
    "from cottage_analysis.io_module.spikes import (\n",
    "    load_kilosort_folder,\n",
    "    get_smoothed_spike_rate,\n",
    ")\n",
    "from cottage_analysis.preprocessing import find_frames\n",
    "from cottage_analysis.imaging.common.find_frames import find_imaging_frames\n",
    "from cottage_analysis.imaging.common import imaging_loggers_formatting as format_loggers\n",
    "\n",
    "\n",
    "monitor_frames_df = synchronisation.find_monitor_frames(\n",
    "    vis_stim_recording=recording,\n",
    "    flexilims_session=flexilims_session,\n",
    "    photodiode_protocol=photodiode_protocol,\n",
    "    harp_recording=harp_recording,\n",
    "    onix_recording=onix_recording,\n",
    "    conflicts=conflicts,\n",
    "    sync_kwargs=sync_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_frames_df = monitor_frames_df[monitor_frames_df.closest_frame.notnull()].copy()\n",
    "monitor_frames_df = find_frames.remove_frames_in_wrong_order(monitor_frames_df)\n",
    "monitor_frames_df.closest_frame = monitor_frames_df.closest_frame.astype(\"int\")\n",
    "harp_ds = flz.get_datasets(\n",
    "    flexilims_session=flexilims_session,\n",
    "    origin_name=harp_recording.name,\n",
    "    dataset_type=\"harp\",\n",
    "    allow_multiple=False,\n",
    "    return_dataseries=False,\n",
    ")\n",
    "if type(harp_ds.extra_attributes[\"csv_files\"]) == str:\n",
    "    harp_files = eval(harp_ds.extra_attributes[\"csv_files\"])\n",
    "else:\n",
    "    harp_files = harp_ds.extra_attributes[\"csv_files\"]\n",
    "\n",
    "\n",
    "# Merge MouseZ and EyeZ from FrameLog.csv to frame_df according to FrameIndex\n",
    "frame_log = get_frame_log(\n",
    "    harp_ds.flexilims_session,\n",
    "    harp_recording=harp_recording,\n",
    "    vis_stim_recording=recording,\n",
    ")\n",
    "\n",
    "\n",
    "# same for SpherePermTubeReward and SpherePermTubeReward_multidepth\n",
    "frame_log_z = frame_log[[\"FrameIndex\", \"HarpTime\", \"MouseZ\", \"EyeZ\"]].copy()\n",
    "frame_log_z.rename(\n",
    "    columns={\n",
    "        \"FrameIndex\": \"closest_frame\",\n",
    "        \"HarpTime\": \"harptime_framelog\",\n",
    "        \"MouseZ\": \"mouse_z\",\n",
    "        \"EyeZ\": \"eye_z\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "if frame_log_z.closest_frame.isna().any():\n",
    "    print(\n",
    "        f\"WARNING: {np.sum(frame_log_z.closest_frame.isna())} frames are \"\n",
    "        + \"missing from FrameLog.csv. This is likely due to bonsai crash at \"\n",
    "        + \"the end.\"\n",
    "    )\n",
    "    frame_log_z = frame_log_z[frame_log_z.closest_frame.notnull()]\n",
    "    frame_log_z.closest_frame = frame_log_z.closest_frame.astype(\"int\")\n",
    "\n",
    "merge_on = \"closest_frame\"\n",
    "\n",
    "frame_log_z.mouse_z = frame_log_z.mouse_z / 100  # convert cm to m\n",
    "frame_log_z.eye_z = frame_log_z.eye_z / 100  # convert cm to m\n",
    "\n",
    "if monitor_frames_df[merge_on].dtype != frame_log_z[merge_on].dtype:\n",
    "    # print a warning if the merge_on column is not the same type in both dataframes\n",
    "    warnings.warn(\n",
    "        f\"WARNING: merge_on column {merge_on} is not the same type in both \"\n",
    "        + f\"dataframes. monitor_frame_df is {monitor_frames_df[merge_on].dtype} and\"\n",
    "        + f\"frame_log_z is {frame_log_z[merge_on].dtype}. Converting to int64.\"\n",
    "    )\n",
    "    # convert both to int64\n",
    "    monitor_frames_df[merge_on] = monitor_frames_df[merge_on].astype(\"int64\")\n",
    "    frame_log_z[merge_on] = frame_log_z[merge_on].astype(\"int64\")\n",
    "\n",
    "vs_df = pd.merge_asof(\n",
    "    left=monitor_frames_df[[\"closest_frame\", \"onset_time\"]],\n",
    "    right=frame_log_z,\n",
    "    on=merge_on,\n",
    "    direction=\"backward\",\n",
    "    allow_exact_matches=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_csvs = harp_dataset.extra_attributes[\"csv_files\"]\n",
    "rewards_logs = {}\n",
    "newparams_logs = {}\n",
    "\n",
    "for csvname, filename in harp_csvs.items():\n",
    "    if \"RewardLog\" in csvname:\n",
    "        rewards_logs[csvname] = pd.read_csv(harp_dataset.path_full / filename)\n",
    "    elif \"NewParams\" in csvname:\n",
    "        newparams_logs[csvname] = pd.read_csv(harp_dataset.path_full / filename)\n",
    "print(\n",
    "    f\"Found {len(rewards_logs)} RewardLog files and {len(newparams_logs)} NewParams files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "t0 = vs_df.harptime_framelog.min()\n",
    "for idepth, (csv_name, df) in enumerate(rewards_logs.items()):\n",
    "    depth = int(csv_name.split(\"_\")[-1][:-2])\n",
    "    rw_time = df[\"HarpTime\"].astype(float) - t0\n",
    "    ax.plot(rw_time, np.ones_like(rw_time) * idepth, \"|\", label=depth)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_xlim(2900, 3200)\n",
    "fig.tight_layout()\n",
    "ax.set_title(\"Reward times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "for idepth, (csv_name, df) in enumerate(newparams_logs.items()):\n",
    "    depth = int(csv_name.split(\"_\")[-1][:-2])\n",
    "    radius = df[\"Radius\"].values.astype(float)\n",
    "    radius[radius < 0] = np.nan\n",
    "    rw_time = df[\"HarpTime\"].astype(float) - t0\n",
    "    ax.plot(rw_time, np.log(radius), \"|\", label=depth)\n",
    "    r = (df.Radius == -9999).astype(int)\n",
    "    corridor_end = np.diff(r) == 1\n",
    "    print(\n",
    "        f\"Depth {depth}: {np.sum(corridor_end)} corridor ends, {np.sum(corridor_end)/8} trials\"\n",
    "    )\n",
    "ax.set_xlim(2900, 3200)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"log(Radius)\")\n",
    "ax.set_title(\"Sphere creation times\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "t0 = vs_df.monitor_harptime.min()\n",
    "for idepth, (csv_name, df) in enumerate(newparams_logs.items()):\n",
    "    depth = int(csv_name.split(\"_\")[-1][:-2])\n",
    "    rw_time = df[\"HarpTime\"].astype(float) - t0\n",
    "    ax.plot(rw_time, df.Z0, label=depth)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_df_by_depth = {}\n",
    "for idepth, (csv_name, param_log) in enumerate(newparams_logs.items()):\n",
    "    vs_df_depth = vs_df.copy()\n",
    "    param_log = param_log.rename(columns={\"HarpTime\": \"stimulus_harptime\"})\n",
    "    if \"Frameindex\" in param_log.columns:\n",
    "        if param_log.Frameindex.isna().any():\n",
    "            print(\n",
    "                f\"WARNING: {np.sum(param_log.Frameindex.isna())} frames are missing from ParamLog.csv. This is likely due to bonsai crash at the end.\"\n",
    "            )\n",
    "            param_log = param_log[param_log.Frameindex.notnull()]\n",
    "            param_log.Frameindex = param_log.Frameindex.astype(\"int\")\n",
    "\n",
    "    vs_df_depth = pd.merge_asof(\n",
    "        left=vs_df_depth,\n",
    "        right=param_log,\n",
    "        left_on=\"closest_frame\",\n",
    "        right_on=\"Frameindex\",\n",
    "        direction=\"backward\",\n",
    "        allow_exact_matches=True,\n",
    "    )\n",
    "    # Rename\n",
    "    vs_df_depth.rename(\n",
    "        columns={\n",
    "            \"closest_frame\": \"monitor_frame\",\n",
    "            \"onset_time\": \"monitor_harptime\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    vs_df_depth.drop(\n",
    "        columns=[\n",
    "            \"harptime_framelog\",\n",
    "            \"harptime_sphere\",\n",
    "            \"harptime_imaging_trigger\",\n",
    "            \"offset_time\",\n",
    "            \"peak_time\",\n",
    "        ],\n",
    "        errors=\"ignore\",\n",
    "        inplace=True,\n",
    "    )\n",
    "    vs_df_by_depth[depth] = vs_df_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_frames(\n",
    "    frame_times,\n",
    "    trials_df,\n",
    "    vs_df,\n",
    "    param_logger,\n",
    "    time_column=\"HarpTime\",\n",
    "    resolution=1,\n",
    "    sphere_size=10,\n",
    "    azimuth_limits=(-120, 120),\n",
    "    elevation_limits=(-40, 40),\n",
    "    verbose=True,\n",
    "    output_datatype=\"int16\",\n",
    "    output=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (df.Radius == -9999).astype(int)\n",
    "corridor_end = np.diff(r) == 1\n",
    "plt.plot(r)\n",
    "plt.plot(corridor_end)\n",
    "print(np.sum(corridor_end))\n",
    "print(np.sum(corridor_end) / 8)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        param_log = get_param_log(\n",
    "            flexilims_session=flexilims_session,\n",
    "            harp_recording=harp_recording,\n",
    "            vis_stim_recording=recording,\n",
    "        )\n",
    "        # TODO COPY FROM RAW AND READ FROM PROCESSED INSTEAD\n",
    "        param_log = param_log.rename(columns={\"HarpTime\": \"stimulus_harptime\"})\n",
    "        if \"Frameindex\" in param_log.columns:\n",
    "            if param_log.Frameindex.isna().any():\n",
    "                print(\n",
    "                    f\"WARNING: {np.sum(param_log.Frameindex.isna())} frames are missing from ParamLog.csv. This is likely due to bonsai crash at the end.\"\n",
    "                )\n",
    "                param_log = param_log[param_log.Frameindex.notnull()]\n",
    "                param_log.Frameindex = param_log.Frameindex.astype(\"int\")\n",
    "\n",
    "        # TODO: check if that shouldn't also happen for protocol_base == \"KellerTube\"\n",
    "        if photodiode_protocol == 5:\n",
    "            vs_df = pd.merge_asof(\n",
    "                left=vs_df,\n",
    "                right=param_log,\n",
    "                left_on=\"closest_frame\",\n",
    "                right_on=\"Frameindex\",\n",
    "                direction=\"backward\",\n",
    "                allow_exact_matches=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
