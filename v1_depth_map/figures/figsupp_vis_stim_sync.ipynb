{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual stimulation synchronization\n",
    "\n",
    "Notebook to get some numbers on frame drop and closed loop VR delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select session\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "from matplotlib import cm\n",
    "from cottage_analysis.analysis import spheres\n",
    "from cottage_analysis.preprocessing.synchronisation import find_monitor_frames\n",
    "from cottage_analysis.preprocessing import find_frames\n",
    "from v1_depth_map.figure_utils import get_session_list\n",
    "import flexiznam as flz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION=10\n",
    "SAVE_ROOT = Path(\n",
    "    f\"/camp/lab/znamenskiyp/home/shared/presentations/v1_manuscript_2023/ver{VERSION}\"\n",
    ")\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"hey2_3d-vision_foodres_20220101\"\n",
    "flexilims_session = flz.get_flexilims_session(project_id=project)\n",
    "sessions = get_session_list.get_sessions(\n",
    "    flexilims_session=flexilims_session,\n",
    "    exclude_sessions=(),\n",
    "    exclude_openloop=False,\n",
    "    exclude_pure_closedloop=False,\n",
    "    v1_only=True,\n",
    ")\n",
    "print(f\"Found {len(sessions)} sessions for closed loop only\")\n",
    "\n",
    "mice = [sess.split('_')[0] for sess in sessions]\n",
    "mice = set(mice)\n",
    "print(f\"{len(mice)} mice\")\n",
    "\n",
    "valid_mice = ['PZAH6.4b', 'PZAG3.4f']\n",
    "sessions_2 = [s for s in sessions if s.split('_')[0] in valid_mice]\n",
    "sessions_5 = [s for s in sessions if s.split('_')[0] not in valid_mice]\n",
    "print(f\"Found {len(sessions_2)} sessions for 2 color square\")\n",
    "print(f\"Found {len(sessions_5)} sessions for 5 color square\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all sessions from 2 color square\n",
    "photodiode_protocol = 2\n",
    "all_sessions_2 = []\n",
    "project_recordings = flz.get_entities(datatype='recording', flexilims_session=flexilims_session)\n",
    "for session in sessions_2:\n",
    "    sess_df = flz.get_entity(name=session, datatype='session', flexilims_session=flexilims_session)\n",
    "    recording = project_recordings[project_recordings.origin_id==sess_df['id']]\n",
    "    recording = recording[recording.protocol=='SpheresPermTubeReward'].iloc[0]\n",
    "    recording = spheres.get_str_or_recording(recording, flexilims_session)\n",
    "    monitor_frames_df = find_monitor_frames(\n",
    "        vis_stim_recording=recording,\n",
    "        flexilims_session=flexilims_session,\n",
    "        photodiode_protocol=photodiode_protocol,\n",
    "        harp_recording=None,\n",
    "        onix_recording=None,\n",
    "        conflicts='skip',\n",
    "        sync_kwargs=None,\n",
    "        verbose=False,\n",
    "    )\n",
    "    monitor_frames_df['session'] = session\n",
    "    all_sessions_2.append(monitor_frames_df)\n",
    "all_sessions_2 = pd.concat(all_sessions_2)\n",
    "\n",
    "summary_df_2 = {}\n",
    "for sess, df in all_sessions_2.groupby('session'):\n",
    "    ifi = np.diff(df['peak_time'])\n",
    "    frame_rate = 1/np.nanmedian(ifi)\n",
    "    avg_frame_rate = 1/np.nanmean(ifi)\n",
    "    skip = ifi > 1.5 / frame_rate\n",
    "    perc_skip = np.sum(skip) / len(skip) * 100\n",
    "    summary_df_2[sess] = dict(frame_rate=frame_rate, avg_frame_rate=avg_frame_rate, perc_skip=perc_skip)\n",
    "summary_df_2 = pd.DataFrame(summary_df_2).T\n",
    "ok = 100 - summary_df_2.perc_skip\n",
    "desc = ok.describe()\n",
    "print(f\"Percentage of frame displayed correctly: {desc['mean']:.2f} +/- {desc['std']:.2f} %\")\n",
    "desc_frame_rate = summary_df_2.avg_frame_rate.describe()\n",
    "print(f\"Average frame rate: {desc_frame_rate['mean']:.2f} +/- {desc_frame_rate['std']:.2f} Hz\")\n",
    "\n",
    "# pick and example session with an average frame rate\n",
    "avg = summary_df_2.avg_frame_rate\n",
    "closest = np.argmin(np.abs(summary_df_2.avg_frame_rate - avg))\n",
    "example_session = summary_df_2.index[closest]\n",
    "print(f\"Example session: {example_session}\")\n",
    "\n",
    "\n",
    "# Get the photodiode trace for the example session for 2 color square\n",
    "from cottage_analysis.io_module.harp import load_harpmessage\n",
    "from cottage_analysis.io_module.visstim import get_frame_log, get_param_log\n",
    "sess_df = flz.get_entity(name=example_session, datatype='session', flexilims_session=flexilims_session)\n",
    "recording = project_recordings[project_recordings.origin_id==sess_df['id']]\n",
    "recording = recording[recording.protocol=='SpheresPermTubeReward'].iloc[0]\n",
    "recording = spheres.get_str_or_recording(recording, flexilims_session)\n",
    "\n",
    "vis_stim_recording = spheres.get_str_or_recording(recording, flexilims_session)\n",
    "harp_message, harp_ds = load_harpmessage(\n",
    "        recording=recording,\n",
    "        flexilims_session=flexilims_session,\n",
    "        conflicts=\"skip\",\n",
    "    )\n",
    "photodiode = harp_message['photodiode']\n",
    "ao_time = harp_message['analog_time']\n",
    "monitor_frames_df = find_monitor_frames(\n",
    "        vis_stim_recording=recording,\n",
    "        flexilims_session=flexilims_session,\n",
    "        photodiode_protocol=photodiode_protocol,\n",
    "        harp_recording=None,\n",
    "        onix_recording=None,\n",
    "        conflicts='skip',\n",
    "        sync_kwargs=None,\n",
    "        verbose=False,\n",
    "    )\n",
    "frame_log = get_frame_log(flexilims_session, harp_recording=recording,\n",
    "        vis_stim_recording=recording,\n",
    "    )\n",
    "\n",
    "# plot the photodiode trace for example session of 2 color square\n",
    "start = len(photodiode) // 2 + 10000\n",
    "samples = 300\n",
    "t_part = 1000 * (ao_time[start:start+samples] - ao_time[start])\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(3,2,1)\n",
    "data = photodiode[start:start+samples].reshape(1, -1)\n",
    "data = np.vstack([np.ones_like(data), data])\n",
    "ax.imshow(data, aspect='auto', cmap='Greys',\n",
    "           extent=[t_part[0], t_part[-1], 0, 2], interpolation='None')\n",
    "ax.plot(t_part, data[1] / data[1].max() + 1, 'k')\n",
    "ax.set_yticks([0.5])\n",
    "ax.set_xlabel('Time (ms)')\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(3,2,3)\n",
    "pt = monitor_frames_df['peak_time'].values\n",
    "ifi = np.diff(pt)\n",
    "t0 = ao_time[start]\n",
    "valid = (pt > t0) & (pt < t0 + 0.3)\n",
    "ax1.plot((pt[valid] - t0), 1/ifi[valid[:-1]], '.k')\n",
    "ax.scatter((pt[valid] - t0)*1000, np.arange(valid.sum()) % 2 *0.8+ 1.1 , c='k')\n",
    "\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Frame rate (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all sessions from 5 color square\n",
    "photodiode_protocol = 5\n",
    "all_sessions_5 = []\n",
    "for session in sessions_5:\n",
    "    project_recordings = flz.get_entities(datatype='recording', flexilims_session=flexilims_session)\n",
    "    sess_df = flz.get_entity(name=session, datatype='session', flexilims_session=flexilims_session)\n",
    "    recording = project_recordings[project_recordings.origin_id==sess_df['id']]\n",
    "    recording = recording[recording.protocol=='SpheresPermTubeReward'].iloc[0]\n",
    "    recording = spheres.get_str_or_recording(recording, flexilims_session)\n",
    "    monitor_frames_df = find_monitor_frames(\n",
    "        vis_stim_recording=recording,\n",
    "        flexilims_session=flexilims_session,\n",
    "        photodiode_protocol=photodiode_protocol,\n",
    "        harp_recording=None,\n",
    "        onix_recording=None,\n",
    "        conflicts='skip',\n",
    "        sync_kwargs=None,\n",
    "        verbose=False,\n",
    "    )\n",
    "    monitor_frames_df['session'] = session\n",
    "    all_sessions_5.append(monitor_frames_df)\n",
    "all_sessions_5 = pd.concat(all_sessions_5)\n",
    "\n",
    "summary_df_5 = {}\n",
    "for sess, df in all_sessions_5.groupby('session'):\n",
    "    ifi = np.diff(df['peak_time'])\n",
    "    frame_rate = 1/np.nanmedian(ifi)\n",
    "    avg_frame_rate = 1/np.nanmean(ifi)\n",
    "    skip = ifi > 1.5 / frame_rate\n",
    "    perc_skip = np.sum(skip) / len(skip) * 100\n",
    "    summary_df_5[sess] = dict(frame_rate=frame_rate, avg_frame_rate=avg_frame_rate, perc_skip=perc_skip, lag=np.nanmean(df.lag))\n",
    "summary_df_5 = pd.DataFrame(summary_df_5).T\n",
    "ok = 100 - summary_df_5.perc_skip\n",
    "desc = ok.describe()\n",
    "print(f\"Percentage of frame displayed correctly: {desc['mean']:.2f} +/- {desc['std']:.2f} %\")\n",
    "desc_frame_rate = summary_df_5.avg_frame_rate.describe()\n",
    "print(f\"Average frame rate: {desc_frame_rate['mean']:.2f} +/- {desc_frame_rate['std']:.2f} Hz\")\n",
    "desc_lag = (summary_df_5.lag *1000).describe()\n",
    "print(f\"Average lag: {desc_lag['mean']:.2f} +/- {desc_lag['std']:.2f} ms\")\n",
    "# pick and example session with an average frame rate\n",
    "avg = summary_df_5.lag\n",
    "closest = np.argmin(np.abs(summary_df_5.lag - avg))\n",
    "example_session = summary_df_5.index[closest]\n",
    "print(f\"Example session: {example_session}\")\n",
    "\n",
    "# get the photodiode trace for example session of 5 color square\n",
    "from cottage_analysis.io_module.harp import load_harpmessage\n",
    "from cottage_analysis.io_module.visstim import get_frame_log, get_param_log\n",
    "sess_df = flz.get_entity(name=example_session, datatype='session', flexilims_session=flexilims_session)\n",
    "recording = project_recordings[project_recordings.origin_id==sess_df['id']]\n",
    "recording = recording[recording.protocol=='SpheresPermTubeReward'].iloc[0]\n",
    "recording = spheres.get_str_or_recording(recording, flexilims_session)\n",
    "\n",
    "vis_stim_recording = spheres.get_str_or_recording(recording, flexilims_session)\n",
    "harp_message, harp_ds = load_harpmessage(\n",
    "        recording=recording,\n",
    "        flexilims_session=flexilims_session,\n",
    "        conflicts=\"skip\",\n",
    "    )\n",
    "photodiode = harp_message['photodiode']\n",
    "ao_time = harp_message['analog_time']\n",
    "running = harp_message['rotary_meter']\n",
    "monitor_frames_df = find_monitor_frames(\n",
    "        vis_stim_recording=recording,\n",
    "        flexilims_session=flexilims_session,\n",
    "        photodiode_protocol=photodiode_protocol,\n",
    "        harp_recording=None,\n",
    "        onix_recording=None,\n",
    "        conflicts='skip',\n",
    "        sync_kwargs=None,\n",
    "        verbose=False,\n",
    "    )\n",
    "frame_log = get_frame_log(flexilims_session, harp_recording=recording,\n",
    "        vis_stim_recording=recording,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the software lag\n",
    "# we get distance from rotary meter and find the frame where this distance is reached\n",
    "dst = harp_message[\"rotary_meter\"].cumsum() * 100\n",
    "running_index = ao_time.searchsorted(frame_log[\"HarpTime\"].values)\n",
    "running_at_frame = dst[running_index]\n",
    "\n",
    "delays = np.zeros_like(running_at_frame) + np.nan\n",
    "for frame, f_series in frame_log.iterrows():\n",
    "    mouse_z = f_series.MouseZ\n",
    "    actual_dst = running_at_frame[frame]\n",
    "    if actual_dst < mouse_z:\n",
    "        continue\n",
    "    delay = 0\n",
    "    findex = running_index[frame]\n",
    "    # look only at moment where the mouse is running > 5cm/s\n",
    "    window = 100\n",
    "    if (dst[findex] - dst[findex - window]) < 5 * window / 1000:\n",
    "        continue\n",
    "    while dst[findex - delay] > mouse_z:\n",
    "        delay += 1\n",
    "    part_searched = dst[findex - delay : findex]\n",
    "    if any(np.diff(part_searched) < 0):\n",
    "        continue\n",
    "    delays[frame] = delay / 1000  # because 1kHz\n",
    "    \n",
    "# plot encoder position and frame log position for example session of 5 color square\n",
    "start = len(photodiode) // 2 + 10000\n",
    "t0 = ao_time[start]\n",
    "p0 = dst[start]\n",
    "samples = 60\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.subplot(1,1,1)\n",
    "plt.plot(ao_time[start:start+samples] - t0, dst[start:start+samples]-p0, label='Encoder position')\n",
    "log_part = frame_log[(frame_log.HarpTime > t0) & (frame_log.HarpTime < t0 + samples/1000)]\n",
    "plt.plot(log_part.HarpTime.values - t0, log_part.MouseZ.values - p0,  label='Frame log position', drawstyle='steps-post')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Position (cm)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add software and display lag to the monitor frames\n",
    "matched_frame_id = monitor_frames_df.closest_frame.values\n",
    "ok = ~np.isnan(matched_frame_id) & ~np.isnan(monitor_frames_df.lag)\n",
    "match_frame_time = np.nan * np.ones(len(ok))\n",
    "match_frame_time[ok] = frame_log.loc[matched_frame_id[ok].astype(int)].HarpTime.values\n",
    "display_lag = monitor_frames_df[\"peak_time\"].values - match_frame_time\n",
    "dl = np.ones(len(display_lag)) * np.nan\n",
    "dl[ok] = display_lag[ok]\n",
    "monitor_frames_df[\"display_lag\"] = dl\n",
    "# then add the hardware lag\n",
    "sl = np.ones(len(display_lag)) * np.nan\n",
    "sl[ok] = delays[matched_frame_id[ok].astype(int)]\n",
    "monitor_frames_df[\"software_lag\"] = sl\n",
    "monitor_frames_df['total_lag'] = monitor_frames_df['display_lag'] + monitor_frames_df['software_lag']\n",
    "\n",
    "w = 7\n",
    "dt = np.nanmedian(np.diff(ao_time))\n",
    "position_ao = np.cumsum(running)\n",
    "rs_filt = (position_ao[w:] - position_ao[:-w]) / w / dt\n",
    "frame_dt = np.nanmedian(frame_log['HarpTime'].diff())\n",
    "frame_log['speed'] = frame_log['MouseZ'].diff() / frame_dt\n",
    "frame_log['speed'] = frame_log['speed'].rolling(3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot main figure\n",
    "fontsize_dict = {\"title\": 7, \"label\": 7, \"tick\": 5, \"legend\": 5}\n",
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "med_ifi = np.median(np.diff(monitor_frames_df.peak_time))\n",
    "start = len(photodiode) // 2 + 6200\n",
    "samples = 500\n",
    "t0 = ao_time[start]\n",
    "t_part = 1000 * (ao_time[start:start+samples] - t0)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "seq = frame_log['PhotoQuadColor'].values\n",
    "seq_ind = frame_log.HarpTime.values.searchsorted(ao_time[start:start+samples])\n",
    "seq_val = seq[seq_ind]\n",
    "shifted_ind = monitor_frames_df.offset_time.values.searchsorted(ao_time[start:start+samples])\n",
    "shifted_seq_ind = monitor_frames_df.closest_frame.values[shifted_ind]\n",
    "shifted_seq = np.zeros_like(shifted_seq_ind) + np.nan\n",
    "shifted_seq[~np.isnan(shifted_seq_ind)] = frame_log['PhotoQuadColor'].loc[shifted_seq_ind[~np.isnan(shifted_seq_ind)]].values\n",
    "pd_part = photodiode[start:start+samples].astype(float)\n",
    "pd_part -= pd_part.min()\n",
    "pd_part /= pd_part.max()\n",
    "\n",
    "## plot the photodiode\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "nper_line = 1\n",
    "data = np.zeros((nper_line * 3 + 2,len(t_part)))\n",
    "data[:nper_line] += seq_val\n",
    "data[nper_line] = np.nan\n",
    "data[nper_line + 1:nper_line * 2 + 1] += pd_part \n",
    "data[nper_line * 2 + 1] = np.nan\n",
    "data[nper_line * 2 + 2:nper_line * 3 + 2] += shifted_seq\n",
    "img = ax.imshow(data, aspect='auto', cmap='Greys_r',\n",
    "           extent=[t_part[0], t_part[-1], 0, 8], interpolation='None')\n",
    "valid_frame = monitor_frames_df[(monitor_frames_df.peak_time > t0) & (monitor_frames_df.peak_time < t0 + samples/1000)]\n",
    "valid_log = frame_log[(frame_log.HarpTime > t0-med_ifi) & (frame_log.HarpTime < t0 + samples/1000 + med_ifi)]\n",
    "frame_log_time = (valid_log.HarpTime - t0 - med_ifi/2)*1000\n",
    "real_frame_time = (valid_frame.peak_time - t0)*1000\n",
    "colors = cm.Greys_r\n",
    "for ind, log in valid_log.iterrows():\n",
    "    if ind in valid_frame.closest_frame.values:\n",
    "        matching = valid_frame[valid_frame.closest_frame == ind]\n",
    "        assert len(matching) == 1\n",
    "        matching = matching.iloc[0]\n",
    "        real_time = real_frame_time.loc[matching.name]\n",
    "        ax.plot([frame_log_time.loc[ind], real_time], [6.4, 4.8], color='k', zorder=-2, lw=1, ls=':')\n",
    "        \n",
    "ax.set_yticks([4, 7.5])\n",
    "ax.set_yticklabels(['Photodiode', 'Sequence'])\n",
    "ax.set_xlim(0, 150)\n",
    "ax.set_ylim(3, 8)\n",
    "ax.set_xlabel('Time (ms)', fontsize=fontsize_dict[\"label\"])\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize_dict[\"tick\"])\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "\n",
    "## plot the running speed or position\n",
    "ax1 = fig.add_subplot(2,2,3)\n",
    "start = len(photodiode) // 2 + 63700 \n",
    "t0 = ao_time[start]\n",
    "samples = 200\n",
    "t_part = (ao_time[start:start+samples] - t0)\n",
    "m_df_part = monitor_frames_df[(monitor_frames_df.onset_time > t0) & (monitor_frames_df.offset_time < t0 + samples/1000)]\n",
    "frame_i = m_df_part.closest_frame.values\n",
    "pos_part = position_ao[start:start+samples].astype(float) * 100\n",
    "log_pos = np.zeros(len(frame_i)) + np.nan\n",
    "log_pos[~np.isnan(frame_i)] = frame_log.loc[frame_i[~np.isnan(frame_i)], 'MouseZ']\n",
    "p0 = log_pos.min()\n",
    "ax1.plot(t_part * 1000, (pos_part - p0), 'k',  lw=1, label='Real position')\n",
    "ax1.plot((m_df_part.onset_time.values - t0) *1000, (log_pos - p0), 'dodgerblue', lw=1, drawstyle='steps-post',label='VR position')\n",
    "ax1.legend(loc='upper left', ncol=1, bbox_to_anchor=(0.0, 1.0,0.9,0.1), labelspacing=0.1,\n",
    "           frameon=False, borderaxespad=0, fontsize=fontsize_dict[\"legend\"])\n",
    "ax1.set_ylabel('Position (cm)', fontsize=fontsize_dict[\"label\"])\n",
    "# ax3.set_ylim(0, 70)\n",
    "common_time = ao_time[start:start+samples].searchsorted(m_df_part.onset_time)\n",
    "pos_common = pos_part[common_time]\n",
    "if False:\n",
    "    ax1twin = ax1.twinx()\n",
    "    ax1twin.plot((m_df_part.onset_time - t0) *1000, pos_common - log_pos, 'indianred', lw=1, drawstyle='steps-post',)\n",
    "    ax1twin.set_ylabel('Position error (cm)', color='indianred')\n",
    "    ax1twin.spines[\"top\"].set_visible(False)\n",
    "    ax1twin.set_yticks([0, 1, 2], labels=['0', '1', '2'], color='indianred')\n",
    "ax1.set_xlabel('Time (ms)', fontsize=fontsize_dict[\"label\"])\n",
    "ax1.spines[\"top\"].set_visible(False)\n",
    "ax1.spines[\"right\"].set_visible(False)\n",
    "ax1.set_xlim(0, 150)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=fontsize_dict[\"tick\"])\n",
    "\n",
    "# Histogram of the lags\n",
    "ax2 = fig.add_subplot(2,2,4)\n",
    "ax2.hist(\n",
    "    1000 * (monitor_frames_df.total_lag),\n",
    "    color=\"k\",\n",
    "    alpha=0.6,\n",
    "    density=True,\n",
    "    bins=np.arange(0, 70),\n",
    "    label=\"Total\",\n",
    ")\n",
    "ax2.set_xticks(np.round(np.arange(10) / frame_rate * 1000).astype(int))\n",
    "ax2.set_xlabel(\"Lag (ms)\", fontsize=fontsize_dict[\"label\"])\n",
    "ax2.set_ylabel(\"Proportion of Frames\", fontsize=fontsize_dict[\"label\"])\n",
    "ax2.set_yticks([0, 0.3])\n",
    "ax2.set_xlim(14, 44)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=fontsize_dict[\"tick\"])\n",
    "ax2.spines[\"top\"].set_visible(False)\n",
    "ax2.spines[\"right\"].set_visible(False)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(SAVE_ROOT/'lag_example.svg', bbox_inches='tight', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2p_analysis_cottage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
